Kto jest zbędny?


od Wiktorii Cukt do krótkiej analizy zjawiska tzw. sztucznej inteligencji i jej społecznego oddziaływania






1. 1999-2000


Na przełomie października i listopada 1999 roku przy kawiarnianym stoliku w ogródku obok ratusza staromiejskiego, siedziby NCK przy ul.Korzennej w Gdańsku, odbyło się spotkanie podczas którego kuratorka CSW Łaźnia, Bożena Czubak zaproponowała grupie artystycznej CUKT udział w wystawie “Negocjatorzy sztuki”. Jako że zbliżały się wybory prezydenckie, naturalnym wydało się nawiązanie do akcji “Antyelekcja” sprzed 5 lat i akcja “wyborcza”. W 1995 kandydatem podczas techno party w Fortach Góry Gradowej był Mikołaj, ale pada pomysł że teraz wszyscy mamy kandydować. Ja zdecydowanie nie mając ochoty na żadne publiczne wystąpienia, stanowczo oponuję: “o nie, ja zrobię sobie jakąś laskę w 3D i ona będzie za mnie gadać”. I tak ziarno zostało rzucone. Od tego momentu zaczął powstawać projekt “Wiktoria Cukt”. Stopniowo rodziła się całościowa koncepcja zakładająca przeprowadzenie symulacji kampanii wyborczej (ze wszystkimi elementami prawdziwej: wiecami wyborczymi w przestrzeni publicznej i galeriach sztuki, kampanią medialną i zbieraniem podpisów na listach poparcia) przed wyborami prezydenckimi w październiku roku 2000. Kampania promowała pomysł posadzenia na fotelu prezydenta RP osoby wirtualnej: Wiktorii Cukt. Sloganem kampanii było: “Politycy są zbędni”, a Wiktoria była interfejsem wyłącznie koncepcyjnego, futurystycznego programu komputerowego o nazwie Obywatelski Software Wyborczy, który miał zastąpić polityka, a w zasadzie wszystkich polityków, ponieważ miał być systemem demokracji bezpośredniej. 


Deskrypcja funkcji OSW oscylowała pomiędzy programem referendalnym wyciągającym średnią arytmetyczną z nadesłanych opinii na różne tematy, a czymś zdecydowanie więcej: połączeniem wyszukiwarki internetowej wyposażonej w funkcje agregujące i kategoryzujące postulaty wyborców z algorytmami uczenia maszynowego w sieciach neuronowych, konstruującymi rozwiązania występujących w tych postulatach różnic i sprzeczności na podstawie wiedzy czerpanej z zasobów internetu i zaawansowanych obliczeń. Tak tworzyłby się program polityczny Wiktorii i tak kształtowane byłyby jej wypowiedzi. Mimo że ze względu na ograniczenia wynikające z natury algorytmów (skutecznych tylko w rozwiązywaniu problemów mieszczących się w ramach matematyki obliczeniowej, w których to ramach godzenie sprzeczności na pewno się nie mieści) OSW był czystą abstrakcją, niemożliwością, to jednak właśnie perspektywa połączenia wzajemnie wykluczających się postulatów i zakończenia konfliktów politycznych, jakkolwiek iluzoryczna i absurdalna by w gruncie rzeczy nie była, stanowiła o jej wyjątkowości i atrakcyjności, była clou jej programu. Ponieważ wtedy sztuczna inteligencja była terminem powszechnie znanym tylko z literatury czy kinematografii fantastyczno-naukowej które nadawały jej atrybuty wszechpotężnego krzemowego umysłu, a jej rzeczywiste realizacje, algorytmy uczenia maszynowego działające w sieciach neuronowych były znane tylko niewielkim grupom specjalistów i rodziły się pomału i opornie gdzieś w zakamarkach laboratoriów, OSW w postaci Wiktorii Cukt był prowokacyjnym symulakrem czegoś co nie istniało, bo istnieć nie mogło, hiperrealną wszechmocną technologią informatyczną, Sztuczną Inteligencją.


Kampania Wiktorii Cukt była akcją artystyczną, realizacją konceptualnego projektu na temat polityki i demokracji, wykorzystującą imitację politycznej kampanii wyborczej promującej ideę Wiktorii Cukt/OSW w przestrzeni publicznej i medialnej, w celu uzyskania zamierzonego efektu. A efektem akcji, w odróżnieniu od prawdziwych kampanii politycznych, nie miał być przecież niemożliwy z powodów formalnoprawnych wybór Wiktorii na prezydenta, tylko wybrzmienie idei projektu w przestrzeni społecznej, a najlepszym dowodem że projekt osiągnął swój cel było ogromne zainteresowanie jakie wzbudził. Projekt był jednym z pierwszych dotyczących problematyki elektronicznej demokracji bezpośredniej, ale przede wszystkim Wiktoria była pierwszym na świecie wirtualnym politykiem jaki pojawił się w przestrzeni medialnej. Implementowała w historii sztuki politycznej ideę obecności w polityce sztucznej inteligencji, a projekt był pytaniem o społeczną percepcję możliwości odegrania przez nią roli politycznej i wykorzystywał kulturowe stereotypy na jej temat. Jego atrakcyjność, a więc skuteczność oddziaływania z premedytacją bazowała na powszechnej ignorancji odbiorców w tej materii, nawet dla opisujących i recenzujących projekt krytyków i dziennikarzy idea elektronicznej demokracji bezpośredniej była nader często egzotycznym horyzontem ich rozumienia zagadnień jakie poruszała jego warstwa merytoryczna.


Krytyczne znaczenie projektu to oczywiste wyeksponowanie sztuczności kampanii politycznych, medialnie wykreowanych kandydatów i populistycznych haseł wyborczych, wieloznaczna krytyka słabości demokracji polegających m.in. także na tym, że każdy wyborca posiada równie ważny głos niezależnie od stopnia obywatelskiego zaangażowania, wykształcenia i, a może przede wszystkim ilorazu inteligencji, oraz pytanie o potencjał społeczny internetu w reformowaniu systemu demokratycznego. Ale także mniej oczywista gorzka konstatacja ogromnej rozbieżności pomiędzy oficjalną a rzeczywistą sytuacją obywateli w systemie demokratycznym. Nazywani przez polityków podmiotem władzy, suwerenem, a w rzeczywistości traktowani jak bezsilny przedmiot ich manipulacji, tak swoim położeniem zdesperowany, że gotowy bezkrytycznie uwierzyć w najbardziej fantastyczne i nierealne obietnice, nawet w futurystyczne fantomy z domeny science fiction, by choć w fatamorganie zobaczyć cień szansy na wyjście z tej matni. Wiktoria była tu tym politycznym mirażem, podtekstowo nierealnym ale tchnącym duchem jaśniejszej przyszłości, zwodniczo świeżą bryzą optymizmu w dusznym i skorumpowanym świecie polityków, nadzieją na technologicznie obiektywny sposób sprawowania władzy. Tym samym projekt wskazywał na fakt, iż politycy w bezwzględnym dążeniu do zdobycia poparcia świadomie tworzą symulacje, iluzje idei czy rozwiązań istniejących, bądź nie, problemów, kłamią z pełną premedytacją kreując pozory które ostatecznie nigdy nie stają się rzeczywistością. Rzekomo rzeczywistość symulakrów to hiperrzeczywistość, a to po prostu rzeczywistość polityczna. Wiktoria jako interface OSW była pytaniem o prawdziwą naturę majaczącej wtedy za horyzontem, wyłącznie mitycznej w świadomości społecznej sztucznej inteligencji, a immanentną cechą projektu było stworzenie iluzji możliwości zaistnienia tej postaci i stojącego za nią programu, rewolucyjnego rozwiązania politycznego, koncepcji rzeczywiście zrealizowanej tylko w stopniu koniecznym i wystarczającym do jej symulowania. Dokładnie tak, jak robią to prawdziwi politycy, w prawdziwej polityce. Parafrazując “V for vendetta” z 2005 r.: politycy kłamią by ukryć prawdę, artyści by ją odsłonić.


OSW miał mieć humanoidalny interface w postaci Wiktorii dlatego, że już w 1950 r. test Turinga dla maszyn aspirujących do umiejętności myślenia (pośrednio weryfikowanej zdolnościami językowymi), polegał na tym że komputer próbuje udawać człowieka[1]. Zresztą, czy trzeba to specjalnie tłumaczyć? Od wiersza poleceń, przez Graphical User Interface, rozmowę z nakładką systemową w postaci np wirtualnej asystentki Siri, aż do modelu AI jako systemu operacyjnego, od biblijnego Golema, przez “autonomicznych” tenisowych sparingpartnerów, do humanoidalnych robotów (Microsoft wypuścił właśnie nowy multimodalny “mózg robota” Magma, a Google DeepMind modele Gemini Robotics), to w gruncie rzeczy wszystko realizacje tego samego fascynującego mitu powtórzenia aktu bożej kreacji[2], oczywiście włącznie z jej ukoronowaniem w postaci człowieka. Pewnie gdzieś tam właśnie wre mrówcza praca, powstają tabuny audiowizualnych botów - wyględnych i wygadanych wirtualnych asystentek, influencerek, terapeutek; całe stada wyspecjalizowanych humanobotów. No i deepfake’ów: niedługo pewnie będzie można immersyjnie “puknąć” online bota 3D dowolnie wybranej celebrytki. W 2024 r. polska firma Humanverse przy pomocy ChatGPT-4, technik 3D, danych z “chmury” i wiedzy historycznej stworzyła w celach edukacyjnych interaktywnego “awatara”[3] (właściwie bota audiowizualnego) Marii Skłodowskiej-Curie. W roku 2000 Wiktoria udawała że w zakresie funkcjonalnego interfejsu OSW, audiowizualnie będzie takim właśnie botem: mój artykuł w dwumiesięczniku komputerowym Digit VI/VII 2000r. (wtedy termin bot dopiero się rodził i nie był jeszcze powszechnie używany). W każdym razie, jeśli program komputerowy miał zastąpić polityka, najlepszym interfejsem była, zacytuję samego siebie z roku 2000: “audiowizualna symulacja pięknej kobiety”.


Animowany wizerunek Wiktorii Cukt stworzony za pomocą edytorów wektorowej grafiki trójwymiarowej był jedynym elementem symulacji interfejsu OSW który rzeczywiście powstał. Jego stworzenie, jako początkowego etapu procesu budowania interaktywnego bota Wiktorii mającego w przyszłości stać się interfejsem programu OSW było właśnie tym koniecznym i najważniejszym elementem uwiarygodnienia symulacji i miało świadczyć o tym, że ten proces już się rozpoczął, że idea projektu nie jest tylko zupełnie czczą obiecanką. Zanim powstał model 3D Wiktorię z konieczności ilustrowało vintage’owe zdjęcie modelki z reklamy szamponu z lat ‘50, jednak już od inicjacji projektu w NCK w Gdańsku, eksponowane były efekty moich prac nad modelem 3D, gdyż dopiero taka forma we właściwy i adekwatny sposób obrazowała fakt, że Wiktoria miała być polityczką o całkowicie cyfrowej proweniencji, nadawała projektowi futurystyczny, pionierski styl, była merytorycznie konieczna i w oczywisty sposób wizualnie definiowała ideę projektu Wiktoria Cukt.






2. 2024-2025


Pod koniec roku 2024 jeden z byłych członków “sztabu wyborczego” Wiktorii Cukt (to brzmi naprawdę ironicznie wobec faktu, że była to co prawda zdecydowanie najbardziej spektakularna, ale też ostatnia akcja grupy CUKT, która z hukiem zakończyła jej 5-letnią działalność), reaktywował projekt i wygenerował Wiktorię Cukt 2.0. To bot głosowy oparty na modelu sztucznej inteligencji tzw. LLM (Large Language Model) z którym można “rozmawiać” (a raczej z niego korzystać), a w celu zilustrowania Wiktorii posługuje się short videos (tzw reels, rolki) wypromptowanymi z generatywnego modelu tzw. generative LLM, po nakarmieniu go zdjęciami Brigitty Schilling, której zdjęcie było inspiracją dla twarzy modelu 3D z 1999/2000 r. Promptowanie modeli AI jest banalnie łatwe i szybkie, ale jedyne co jest w tym w pewnym sensie “intrygującego”, to skuteczna eliminacja roli człowieka, tj. grafika[4], z procesu w tym wypadku wy-tworzenia symulacji. Bo jest to tylko taka sama symulacja (pomijając fakt że na Wiktorię-Superinteligencję nikt się dzisiaj nie nabierze), wersja 2.0 także nie jest funkcjonalnym botem audiowizualnym, jakim w 2000 r. Wiktoria udawała że będzie. Choć teraz stworzenie takiego bota jest jak najbardziej możliwe[5], wersja 2.0 nim nie jest, nie można z nią “porozmawiać” widząc i słysząc ją w czasie rzeczywistym tak jak z botem Marii Skłodowskiej, bo jego wyprodukowanie wcale nie jest takie proste. Nie tak proste jak banalne promptowanie filmów video w gLLM (masz tu zdjęcia i zrób mi “rolkę” taką a taką[6]). Wznowienie tego udawania po 25 latach nie wnosi absolutnie niczego nowego, może poza nie sformułowanym przez wytwórcę ale cisnącym się na usta, pasującym jak ulał sloganem: “twórcy są zbędni”.


Wytwórca WC 2.0 twierdzi że ona “dopiero teraz działa”. Nie działa, bo nie jest audiowizualnym botem. Ale gdyby nawet była, to przede wszystkim chodzi przecież o pierwszoplanową kwestię obiecanego wszystkim wyborcom konsensusu, pogodzenia sprzeczności w ich poglądach, które może i leży w granicach wyobraźni, ale poza granicami praw fizyki, matematyki i logiki, a prawa te determinują dostępną technologię zawsze, nie tylko w 2000 r., ale też tu i teraz i w przewidywalnej przyszłości, więc jej ograniczenia nie zniknęły nagle jakimś cudownym sposobem kiedy pojawiła się AI. A przecież w kampanii Wiktorii z 2000 r. esencją jej programu była deklaracja dokonania syntezy wzajemnie sprzecznych poglądów politycznych. A żeby Wiktoria mogła spełnić swoje obietnice i połączyć przeciwieństwa, gdyby w ogóle mogłoby to być możliwe, musiałaby szukać rozwiązań poza działem obliczeniowym matematyki, być jakimś hipotetycznym kwantowym hiperkomputerem, zdolnym przeprowadzać hiperobliczenia o klasie złożoności wykraczającej daleko poza możliwości algorytmów[7] wykonywalnych na maszynach Turinga, w tym oczywiście również algorytmów uczenia maszynowego w sieciach neuronowych. Ograniczenia algorytmów w rozwiązywaniu problemów wynikają z ich natury, a nie z zasobów komputerowych (Teza Churcha-Turinga), tu nie pomoże wzrost mocy obliczeniowej czy dołożenie pamięci, ani choćby i największa dokładka danych. Entuzjastów AI po otrzeźwienie odsyłam do książki Rogera Penrose’a “Nowy umysł cesarza” z 1989 r. Gdyby likwidacja podziałów politycznych czy nierozwiązywalnych problemów społecznych dała się obliczyć komputerowo, dawno żylibyśmy w Arkadii.


Ważniejsze jednak że Wiktoria Cukt nie była przecież politykiem nowego typu, a awangardowym projektem artystycznym, zaangażowaną społecznie sztuką polityczną o ogromnym ładunku krytycznych wieloznaczności. Znaczenie i siła oddziaływania projektu wynikały przede wszystkim z faktu, iż w roku 2000 Wiktoria mogła wiarygodnie symulować, że stanie się wirtualnym politykiem rozwiązującym kontradyktoryjności polityczne, sztuczną super inteligencją, bo domeną sztucznej inteligencji była w owym czasie literatura fantastyczno-naukowa i laboratoryjne sieci neuronowe, a nie jak obecnie cały świat i niemalże wszystkie aspekty ludzkiego życia. Wtedy opinia publiczna miała o naturze AI tylko zupełnie mgliste, stereotypowe wyobrażenie utworzone na podstawie fantastycznonaukowych fikcji literackich, w powszechnym mniemaniu AI jawiła się jako super umysł zdolny pogodzić wszelkie sprzeczności, więc idea Wiktorii Cukt była przekonująca i niosła ze sobą nadzieję na nową jakość w życiu społecznym i polityce, na pozbawiony ludzkich przywar w pełni demokratyczny sposób sprawowania władzy. W roku 2000 projekt jako symulacja mógł być wiarygodny, zyskując tym samym głęboki sens krytyczny i wartość artystyczną, której reaktywacja projektu nie ma, w niezmienionej formule jest obecnie niewiarygodna, ponieważ jest nieadekwatna do natury i ograniczonych możliwości AI, oraz świadomości społecznej w tej materii. Powszechna świadomość faktu, że AI jest jedynie bardzo szybką, ale ułomną asystentką, a w żadnym razie nie super umysłem i potencjalnym nowym rodzajem przywódcy politycznego, czyni reaktywację projektu w oryginalnej formule niewiarygodną, a w konsekwencji nieskuteczną jako idea potencjalnie rewolucyjnych zmian politycznych. Dosłowne powtórzenie projektu, prosta, niczym nie uzasadniona redundancja, powielanie założeń, pomysłów i większości elementów projektu tak, jak gdyby świadomość społeczna zupełnie nie uległa zmianie, a postęp dotyczył jedynie dostępnych narzędzi, czyniących symulację, dzięki generatywnej AI, banalnie prostą w wykonaniu i nieobciążoną prawami autorskimi twórców, jest nadmiarowe i bezwartościowe artystycznie. Wiktoria Cukt 2.0 to klon projektu z 2000 r., którego odtwarzanie w formule sprzed ćwierćwiecza jest obecnie działaniem czysto koniunkturalnym, całe parseki oddalonym od krytycznych znaczeń awangardowej wizji oryginału, wartości artystycznej pierwowzoru.


Ponowna realizacja jeden do jednego pomysłu z 2000 r. jest pozbawiona w zasadzie wszystkich walorów artystycznych oryginału. Nie dodaje żadnych nowych wartości krytycznych i jako sztuka polityczna jest po prostu wtórna, nie zadaje żadnych nowych pytań, ma literalnie zerową oryginalność i taką samą liczbę elementów nowych pomimo nowych okoliczności, ten “replay jest zbędny”. Ale nie tylko. Wytwórca wersji 2.0 najwyraźniej zachwycony łatwością i szybkością uzyskiwania zadowalających go rezultatów za pomocą bota głosowego i tzw transformerów dekodujących gLLM, zapamiętale promptując paradoksalnie chyba nie zauważył, że minęło 25 lat i okoliczności diametralnie się zmieniły, na część pytań jakie stawiał projekt padły już odpowiedzi, w międzyczasie sztuczna inteligencja już powstała i ogólnie wiadomo czym jest[8], a internet okazał się przede wszystkim seo-click-biznesem i superszybką pocztą pantoflową, maglem do potęgi n-tej. Reaktywacja Wiktorii Cukt w wersji 2.0 w tak epigońskiej i trywialnej we współczesnym kontekście formie w oczywisty sposób nie tylko obnaży swoją bezsilność wobec rzeczywistości politycznej, ale najgorsze w niej jest to, że może w niekorzystny sposób wpłynąć na zrozumienie i właściwą ocenę, z dzisiejszej perspektywy, jakie znaczenie i siłę oddziaływania miał projekt w roku 2000, jej efektem ubocznym może okazać się zniweczenie jego reputacji. Wiktoria 2.0 wywołuje przykre wrażenie oportunizmu, płyniecia z prądem, korzystania z mody na AI i bezprecedensowej popularności projektu sprzed ćwierćwiecza. Choćby zbliżony poziom zainteresowania jest zresztą dziś całkowicie nieosiągalny, z upływem lat rzeczywistość się zmieniła i egzotyczna w 2000 r. sztuczna inteligencja teraz hula wszędzie aż (nie)miło, wręcz już spowszedniała, a niedługo zacznie wywoływać odruch wymiotny.


Wytwórca wersji 2.0 nie podejmuje nawet najmniejszej próby, by uzasadnić w kategoriach artystycznych przyczynę reaktywacji projektu w zupełnie niezmienionej formie, zapewne dlatego, że ta reaktywacja jest tylko rodzajem artystowskiej zabawy pseudo-politycznej, skazanej na porażkę nie tylko artystyczną, ale także w sferze polityki. AI może zastąpić ludzi tylko w sensie powielania ludzkich błędów i nie jest w stanie rozwiązać żadnych poważnych problemów politycznych, których nie rozwiązaliby ludzie. WC 2.0 realnie nie zdziała więcej niż byle w miarę rozgarnięty polityk, powiem więcej - zdziała znacznie mniej. “Politycy AI są zbędni” i dotyczy to znakomitej większości tego typu inicjatyw, a na pewno tych próbujących nierozsądnie i na wyrost używać algorytmów w działaniach okołopolitycznych i wmawiających odbiorcom że ejaj ich w jakikolwiek sposób zbawi. Choć Wiktoria w roku 2000 to właśnie robiła, to kontekst zmienia wszystko, wtedy ta symulacja mówiła wiele o ówczesnej kondycji społeczeństwa, demokracji i technologii, a po upływie ćwierćwiecza to wszystko diametralnie się zmieniło, a pytania i wyzwania współczesności są zupełnie inne, może nawet krańcowo odmienne. Uderzająca jest świadomość degradacji projektu w wersji 2.0, faktu że Wiktoria która była pierwsza i jedyna na świecie i niosła światło technologicznej nadziei jakkolwiek złudna by się ona nie okazała, teraz kiedy technologia zawitała pod strzechy i okazało się że spodziewana wielka dama intelektu jest jakimś mało rozgarniętym kocmołuchem, oraz pojawiło się całe mnóstwo pokrewnych inicjatyw quasi politycznych, jako jedna z wielu, zdeprecjonowana i zmarginalizowana przez okoliczności, specyficznym stylem agitki politycznej, brzmiącym jak cybernetyczna wersja partyjnej nowomowy z epoki słusznie minionej, wygłasza puste propagandowe komunały, mgliste deklaracje rzekomej progresywności i mętne obietnice, a jej jedyna konkretna i sensowna propozycja to tworzyć forum dyskusyjne. W 2025 r. to szokująca rewelacja, wręcz rewolucja. Naprawdę, to co było awangardą 25 lat temu, niosąc choć nikły i złudny, ale jednak odblask prawdopodobnej nowej nadziei, powtórzone dziś jak zwykle okazuje się rozczarowującym banałem i żadnego wrażenia na nikim nie robi. Obietnica zrealizowania koncepcji rozwiązującej polityczny dualizm “superinteligencji z ludzką twarzą” była mentalną kiełbasą wyborczą, mrzonką uświadamiającą stan rzeczywistości społecznej, a realnie nie było to możliwe w 2000 r., nadal nie jest i nigdy nie będzie. Hasło “Politycy są zbędni” było przynętą, blefem, symulacją, a realizacja nieziszczalnej idei z oczywistych względów nigdy nie była celem projektu Wiktoria Cukt. Twierdzenie, że można tę wizję zrealizować to albo wynik niewiarygodnie powierzchownej kwerendy i naiwnego zachłyśnięcia się pozornie “cudowną” ejaj, albo po prostu kłamstwo, ale nie jak 25 lat temu odsłaniające kawałek prawdy o społeczeństwie i systemie politycznym, a kryjące czysty oportunizm[9]. Wiktoria Cukt na pewno nigdy nie była instrukcją wejścia do świata polityki w przyszłości, a choć wytwórca wersji 2.0 poniekąd zdaje sobie sprawę z ograniczeń AI, to deklaruje enigmatyczną “wiarę w AI” mimo iż nie posiada żadnej wizji rozwiązania wspomnianych niemożności w funkcjonowaniu Wiktorii jako polityka, a modus operandi jakim nieopatrznie w publicznej wypowiedzi obdarza Wiktorię Cukt 2.0 to prosta droga do całkowicie sprzecznej z założeniami oryginału autokracji spod znaku AI. Może powinien raczej użyć nazwy “Stalin 2.0”? Przy okazji: element satyry społeczno-politycznej jest dziś poza tym że wtórny, to w obecnych okolicznościach kompletnie nietrafiony kontekstowo. Tak czy siak, bot ejaj cudów nie uczyni, a Wiktoria Cukt była zabawnym, wiele o kondycji społeczeństwa i demokracji mówiącym pomysłem który wybrzmiał dawno temu, po co to powtarzać do znudzenia.






3. 2025…


“Aby przeleciał wszystka ducha skrzydłem. Strofa być winna taktem, nie wędzidłem.”[10]




Czas zostawić Wiktorię w muzealnym spokoju, tragikomizm tej sytuacji polega na tym że idea projektu z jednej strony pozornie została zrealizowana w postaci AI, ale z drugiej w związku z naturą modeli w sposób który wypaczył i w pewnym sensie zdeprecjonował jej przekaz, więc trudno wyobrazić sobie racjonalnie uzasadniony i adekwatny do obecnej sytuacji powrót Wiktorii. Ratunkiem i może nawet ostatecznym nomen omen triumfem byłoby dla niej tylko powstanie autentycznej sztucznej superinteligencji. Przyjrzyjmy się więc aktualnym modelom sztucznej inteligencji w miarę możliwości obiektywnie i nieco wnikliwiej, żeby uzyskać jako takie pojęcie czym naprawdę są, czym na pewno nie, jak działają, na czym polega interakcja z nimi i jakie są niektóre społeczne reperkusje tego zjawiska; temat jest na pewno aktualny i może nawet fascynujący, ale z pewnych względów w gruncie rzeczy nie aż tak jak mogłoby się na pozór wydawać.


Narracja marketingowa lobby czerpiącego korzyści z AI przedstawia ją jako “nową jakość”, super zaawansowaną technologię informatyczną, której możliwości mają jakoby lada chwila sprawić że ludzkość “sięgnie gwiazd”, a która już teraz zaczyna być znaczącym i wkrótce absolutnie nieodzownym elementem nieomal wszystkich obszarów ludzkiego życia. I faktycznie liczba możliwych zastosowań jest może policzalna, ale naprawdę ogromna. Coraz bardziej zaawansowane algorytmy uczenia maszynowego puszczone w ruch w kolosalnie rozbudowywanych na różne, coraz to nowe sposoby sieciach neuronowych mogą wykonywać bardzo szeroki wachlarz zadań: w internecie są wszędzie, w silnikach wyszukiwarek, w schematach targetowania treści i reklam, służą i hakerom i cyberbezpieczeństwu, chatboty zajmują się obsługą klienta, “porozmawiają” z tobą i doradzą bez mała we wszystkim, zapewnią wsparcie psychologiczne, przeprowadzą kwerendę i opracują bardzo szeroki wachlarz tematów, a gLLM’y namalują i zagrają prawie wszystko co chcesz, zrobią ci film na podstawie paru obrazków i/lub promptu, a nawet wyprodukują w pełni funkcjonalną grę. Modele są coraz bardziej wielofunkcyjne, mogą sterować[11] “autonomicznymi” wielozadaniowymi robotami, obsługują rozbudowane systemy nadzoru  publicznego i rozpoznawania zagrożeń, przetwarzają ogromne ilości danych, generują czasem nawet “pomysłowy” kod programistyczny czy inne treści i wielokrotnie przewyższają człowieka w szybkości działania, a czasem i jakości wyników wykonywanych poleceń, od prostych po bardzo złożone, bo mają już pełną “autonomię” w budowaniu procesu rozwiązywania skomplikowanego zadania poprzez dzielenie zawiłych problemów na mniejsze składowe.


Pomijając fakt, że uczenie maszynowe i sieci neuronowe znajdowały wiele zastosowań i były wdrażane na wielu polach zanim marketing podchwycił chwytliwy fantastycznonaukowy termin Artificial Intelligence, to od pewnego czasu rzeczywiście imponująca technologia, która użyta w odpowiedni sposób może przynieść wiele dobrego, może być fenomenalnie użytecznym narzędziem w biznesie, przemyśle czy infrastrukurze. Jest też, czasem nawet z powodzeniem stosowana np. w diagnostyce medycznej i opracowywaniu nowych metod terapii i w wielu innych dziedzinach nauki, umożliwiając bezprecedensowe osiągnięcia. W 2024 r. Nagrodę Nobla w dziedzinie chemii otrzymali po połowie D.Baker i duet D.Hassabis/J.Jumper: Baker za algorytmiczne projektowanie nowych białek (np. do tworzenia nanomateriałów), a pozostali dwaj za opracowanie modelu AlphaFold2, dzięki któremu na podstawie sekwencji aminokwasów byli w stanie przewidzieć strukturę 200mln białek znanych nauce (model wspomaga m.in. tworzenie enzymów rozkładających plastik). Choć można to oceniać zarówno negatywnie jak i pozytywnie to bezsporny jest fakt, że ejaj to też naprawdę fantastyczny generator zysków: 100 czołowych start-upów dochodzi do rocznego przychodu 5mln$ w dwa lata (na topie jest integracja LLM-ów z procesami biznesowymi w coraz większej ilości branż). Wrażenie robi werbalna elastyczność i w.zw. z tym potencjalna użyteczność[12] modeli LLM. Z ChatGPT-4 można kilkoma kliknięciami zrobić filozofa-narkomana na grzybkach albo cynicznego mizantropa, może gaworzyć dowcipnie, ziać hejterskim jadem, być poetą-grafomanem, profesorem prawa albo entuzjastą sztuki, napisze za Ciebie i maturę z geografii i list miłosny (ale ciągle pozostaje w tym ćwierćinteligentem, czasem też stwierdzi że np. “wszystko jest kozożerne” albo demencyjnie zapomni jakie było pytanie). Natomiast fetyszyzowanie ejaj nie przyniesie nic dobrego, jedynie rozczarowanie i regres, kiedy napompowana marketingiem jak ryba rozdymka kompresorem samochodowym, nieuchronnie pęknie. W magazynie Life z 1970 r. Marvin Minsky przewidywał że AI osiągnie ogólną inteligencję przeciętnego człowieka w ciągu trzech do pięciu lat… Oczywiście balonik pękł i na blisko 20 lat zapanowała pierwsza "epoka lodowcowa AI". W czasach kiedy Penrose pisał swoją książkę (1989) nastąpił krótkotrwały renesans, zakończony przez kryzys "dot-comów" (2001). Nadeszła druga epoka lodowcowa, która trwała do ok 2020 roku i debiutu chata GPT-3. Zarysowuje się tu pewna tendencja… 


Żeby móc rzetelnie ocenić jak daleko sztucznej inteligencji do inteligencji, musimy zrozumieć na jakiej zasadzie działa. Pomimo biznesowo motywowanych zabiegów i narracji marketingowych w fałszywym świetle przedstawiających możliwości i potencjał AI, tak naprawdę modele językowe LLM (tzw. transformery), choć mogą wydawać się “inteligentne” i czasami aż trudno oprzeć się wrażeniu, że rozumieją znaczenie słów które składają w zdania[13], są w istocie tylko algorytmicznymi procedurami obliczającymi (token po tokenie) statystyczne prawdopodobieństwo następstwa słów, aż do tokenu EOS (end of sequence i wyciągasz “z pudełka” gotowe wypracowanie), nauczonymi tego procederu, z naruszeniem praw autorskich, na gargantuicznych zbiorach danych. Trzeba tu zaznaczyć, że skomplikowanie algorytmów działających obecnie w sieciach neuronowych i generowanie przez modele tzw. tokenów wewnętrznych powoduje, że nie można w sposób bezpośredni prześledzić od początku do końca ścieżki realizacji zadania, w tym celu potrzebne są ingerencje mogące zakłócać ten proces. Ogólnie rzecz ujmując choć najnowsze wersje modeli LLM działają wielowątkowo i częściowo poza ludzką kontrolą, a ich algorytmy podobno poniekąd wykraczają poza matematykę statystyczną, i może nawet, w ograniczonym zakresie są zdolne do czegoś w rodzaju generalizacji, to ich działanie w oczywisty sposób ogranicza się do matematyki obliczeniowej w ramach modelowania języka naturalnego, abstrakcja jest dla nich abstrakcją, tak samo jak kompletnie obcy jest im platoński świat idei obecny w ludzkim umyśle, czy aprioryczna intuicja aksjomatyczna, tak matematyczna jak i fizyczna, a nawet banalne dla biologicznego mózgu uczenie przez analogie. Kolejne etapy rozwoju, elementy składowe AI, jak rekurencyjne sieci Hopfielda, maszyna Boltzmanna i uczenie głębokie, aż do obecnej postaci ciągle ledwo “kręcą się” wokół zagadnień dotyczących tych zagadek, a ich zdolności asocjacyjne są nieskończenie nikłe w porównaniu z biologicznymi mózgami. Mówiąc w skrócie mózg biologiczny na bazie śladowych ilości danych i “zasobów obliczeniowych”, oraz przy minimalnym zużyciu energii potrafi dokonać operacji, które są niedostępne dla algorytmów w sieciach neuronowych wyposażonych w nieporównywalnie większe zasoby, analizujących kosmiczne ilości danych i pobierających gigantyczne ilości energii i nikt nie wie, i być może nigdy się nie dowie jak to robi. Więc wbrew hurraoptymistycznym, niczym nie popartym przewidywaniom nic nie wskazuje na to, żeby sztuczny “mózg” krzemowy[14] miał jakiekolwiek szanse dorównać biologicznemu, żeby w ogóle kiedykolwiek mogło się tak stać.


W tym miejscu warto wspomnieć o związku, bądź jego braku, języka z procesami myślenia. To ważny, także w kontekście oceny (nie)przydatności testu Turinga[15] lingwistyczno-filozoficzny temat rzeka, ale potrzebne jest choć przybliżone określenie czy “myślimy słowami” i język to jedyny wyznacznik myślenia (kognitywizm), czy myślenie nie ma nic wspólnego z werbalizacją i jak twierdził Noam Chomsky poznanie i język są wzajemnie niezależne (generatywizm), choć to dualizm będący poniekąd odbiciem filozoficznej dychotomii empiryzmu i idealizmu, więc trudno spodziewać się możliwości obiektywnego rozstrzygnięcia tych kwestii. Myślenie można opisać jako proces psychiczny, łączący wiele przenikających się wzajemnie elementów poznawczych (jak pojęcia, opinie, bodźce zmysłowe i emocje) w sekwencje tworzące zbiory znaczeń, niekoniecznie związanych z rzeczywistością realnego, fizycznego świata, równie dobrze mogą dotyczyć zbiorów abstrakcyjnych, jak choćby matematyka abstrakcyjna[16]. Nawiasem mówiąc znaczenia wynikające z procesu myślenia, a raczej jego zaburzeń, mogą niestety przyjmować formę iluzji, chorobliwych wizji rzeczywistości (m.in. pareidolia, podatność na kompletnie nonsensowną część teorii spiskowych, choroby psychiczne itd), więc wydaje się że pomimo iż procesu myślenia do końca nie rozumiemy (piękny paradoks, nie rozumiemy jak rozumiemy) to w sensie podatności na zaburzenia nie jest on jakoś zasadniczo odmienny od innych dobrze poznanych procesów fizjologicznych. Trudności, czy wręcz niemożności w badaniu procesów umysłowych wynikają zapewne w największej mierze z faktu że podmiot badający, jednocześnie będąc przedmiotem badań znajduje się wewnątrz badanego zbioru i w związku z tym nie może uzyskać pełnego, obiektywnego obrazu całości zbioru (zupełnie jak w twierdzeniach Godla).


Z jednej strony istnieje kognitywna hipoteza Sapira-Whorfa której autorzy, jak na lingwistycznych ekspertów przystało, przypisują leksykalno-gramatycznym strukturom języka fundamentalną rolę w kształtowaniu sposobu myślenia, a nawet postrzegania świata. Językowy determinizm silniej, a relatywizm słabiej wiąże kolektywny system symboliczny jakim jest język z jednostkową percepcją i interpretacją zarówno świata, jak i własnego “ja”, więc np. osoby dwujęzyczne rzekomo mają wykazywać lepsze umiejętności poznawcze i elastyczność myślenia. Zwodniczo charyzmatyczny film “Arrival”[17] Denisa Villeneuve’a idzie jeszcze dalej, sugerując wpływ języka nie tylko na postrzeganie rzeczywistości w chwili obecnej czy przeszłości, lecz po prostu możliwość uzyskania za jego pomocą wglądu w przyszłość jako składnika teraźniejszości (kolejny temat rzeka: czas i jego percepcja, fizyka kwantowa, determinizm, wolna wola, paradoksy chronoklastyczne itd). W każdym razie myślenie ma jednak niewątpliwy, w dodatku wzajemny związek z językiem, jaki by on nie był, także z uniwersalnym językiem matematyki czy muzyki, albo językiem czy “mową” ciała i wszystkimi innymi pozawerbalnymi kanałami komunikacji.


Równie niewątpliwy jest jednak fakt, że proces myślenia wykracza poza język czy inne formy komunikacji, że jest bezpośrednio związany ze świadomością, istnieniem jako takim, wewnętrzną rzeczywistością umysłu, ze zjawiskami będącymi źródłem koncepcji idealistycznych w filozofii i jak na razie przynajmniej poza sferą możliwości pełnego zrozumienia i opisu na poziomie biologicznym, ale istniejącymi w obrębie ludzkiego doświadczenia, jestestwa, procesów umysłowych o których być może więcej wie jakiś osamotniony, anonimowy i niepiśmienny, ale świadomie uważny patagoński pasterz niż cała katedra językoznawstwa czy filozofii Uniwersytetu Yale. Myślenie to nie tylko realizowanie zadań, jak zaplanowanie podróży czy rozwiązanie równania, myślenie trwa cały czas, niezależnie od stanu świadomości, dominującej długości elektromagnetycznie odczytywalnych fal mózgowych wytwarzanych przez elektryczną aktywność mózgu, istniejąc nie można nie myśleć, można tylko być bardziej lub mniej świadomym pasażerem bądź kierowcą tego wehikułu w ciągłym ruchu jakim jest umysł. Deprywacja sensoryczna albo głęboka medytacja może powodować przejście funkcjonowania mózgu w długości fal theta czy nawet delta, charakterystyczne dla głębokiego snu fazy NREM. Wyciszenie funkcji mózgu związanych z aktywnością tak fizyczną jak psychiczną, zanik tego mniej lub bardziej głośnego wewnętrznego monologu który na co dzień, przy długościach fal alfa, beta i gamma utożsamiamy z myśleniem, może wywoływać stany subiektywnego poczucia “przebudzenia” czy “wglądu w naturę rzeczy poza czasem”, a jednocześnie w pełni rozbudzonej sensoryczności, pogłębionego odczucia istnienia tylko “tu i teraz”. Jednak to głębokie, wewnętrzne poczucie jaźni uwolnionej od powierzchownego ego, wielopoziomowa samoświadomość to nadal myślenie, forma aktywności mózgu pogrążonego w samym sobie. Myślenie w tym znaczeniu nie ma absolutnie nic wspólnego z jakimkolwiek językiem czy innym kanałem komunikacji, jest po prostu pulsem żyjącego mózgu[18].


Więc jak zasada działania ejaj, ta statystyczna metoda zestawiania słów, ten dobór następującego po poprzednim słowa tak naprawdę jedynie na podstawie prawdopodobieństwa jego wystąpienia w materiale szkoleniowym, ma się do rozumienia języka, odpowiedzcie sobie sami. Fakt że matematyczne modelowanie struktur językowych do pewnego stopnia jakoś działa, świadczy tylko o ograniczonej komunikatywności języka, nie o tym że AI w jakikolwiek sposób chociażby symuluje sposób w jaki językiem posługuje się człowiek, o innych funkcjach umysłowych nawet nie wspominając. To ułomności formy komunikacji jaką jest język sprawiają, że proces który polega wyłącznie na analizie statystycznej może układać sensowne i logiczne zdania symulujące poprawne ciągi myślowe. Tego Alan Turing zdaje się nie przewidział opracowując swój test, którego zaliczenie w żaden sposób nie dowodzi rozumowania maszyny, dowodzi tylko możliwości wystarczająco sprawnego dla przeprowadzenia symulacji manipulowania językiem naturalnym poprzez procedury obliczeniowe. Używanie słowa “myślenie” jest w tym kontekście bezczelnym nadużyciem, profanacją. Procesy które odbywają się wewnątrz sieci neuronowych w najlepszym razie tak się mają do myślenia, jak opowiadanie o budowaniu zamków z piasku na plaży w Dębkach do faktycznego budowania piramid w Gizie.


Test “gra w naśladownictwo” opracowany przez Alana Turinga jako werbalny sprawdzian zgodności inteligencji maszynowej z inteligencją ludzką, wyznaczył kontekst zagadnienia i zdefiniował kierunek rozwoju AI, kładąc nacisk na komunikacyjną sprawność maszyn i sprowadzając główny wątek prac nad ejaj na do dziś kontynuowane tory rozwijania zdolności algorytmicznego operowania językiem naturalnym, które jakoby mają dowodzić posiadania przez te procesy atrybutów inteligencji. Fakt iż obecnie najbardziej zaawansowane modele są w zasadzie w stanie przejść test Turinga świadczy tylko o tym, że tak pomyślany egzamin może w najlepszym razie dowieść zdolności maszyny do skutecznego symulowania inteligencji przy pomocy matematycznego modelowania języka naturalnego, w żadnym razie nie dowodzi że procedury które wykonuje maszyna rzeczywiście wykazują jakiekolwiek cechy inteligencji jako takiej, nawet w wymiarze werbalnym. To powierzchowne i z gruntu antropocentryczne wzorowanie inteligencji maszyn na ograniczonym do werbalnej sprawności komunikacyjnej wycinku inteligencji ludzkiej może być podstawową, pierwotną barierą radykalnie ograniczającą spektrum możliwych sposobów rozumienia zagadnienia sztucznej inteligencji i tworzenia inteligentnych maszyn. Tak wyznaczone ramy pokutują do dziś, wyznaczyły główny obszar myślenia o AI i choć przyczyniły się do stworzenia utylitarnego narzędzia o imponujących możliwościach, a sama koncepcja statystycznej analizy i modelowania języka przyniosła niebywałe efekty, to w kwestii stworzenia prawdziwej sztucznej inteligencji mogą być ślepym zaułkiem.


Wynik testu skojarzeń słownych przeprowadzony na modelu AI byłby całkowicie zależny od materiału szkoleniowego i wprowadzonego promptu, określającego oczekiwane cechy modelu, ale wbrew pozorom nie oznacza to tylko że nie ma on konkretnych parametrów “osobowości”, ale że w ogóle nie może posiadać ani osobowości, ani inteligencji ani jakichkolwiek innych cech, nie tylko umysłowych samoistnego bytu na innym niż symboliczny poziomie, że jest tylko funkcją, rekurencyjnym odbiciem znaku w lustrze nieskończoności, symulakrem w hiperrzeczywistości. Bezpostaciowy w każdym możliwym znaczeniu fantom, iluzja podmiotu jakiego fatamorganę tworzą poprzez wytworzenie złudzenia procesu komunikacji w percepcji użytkownika algorytmy uczenia maszynowego wykonywane w sieciach neuronowych, z definicji nie może wykroczyć poza symulację i uzyskać jakichkolwiek jakości, czy mówimy o inteligencji czy w ogóle o tożsamości. Czy ejaj może powiedzieć: ja? Ejaj jest tylko emulatorem procesu komunikacji w percepcji użytkownika, symulacją nie tylko inteligencji ale pośrednio jestestwa. Podstawowa przyczyna zaburzonego postrzegania AI przez użytkownika to specyficzna rola jaką w świadomości pełni proces komunikacji, będący dla umysłu jedyną nie fizyczną poszlaką istnienia zewnętrznego świata i innych bytów i która oznacza że chodzi tu tylko o symulacyjną sprawność algorytmów w ramach “okowów” języka naturalnego: dla człowieka język jest restrykcją[19], dla ejaj jest inherentnym całokształtem pozornego “istnienia”. Przecież nikt nie podejrzewa i nie ma wrażenia że autonomiczny pojazd jest inteligentny, chociaż pełni te same funkcje co inteligentny kierowca, a wymagają one posiadania innych, ale nie mniej, a może bardziej zaawansowanych kompetencji niż prowadzenie rozmowy, właśnie dlatego że pełnienie tej roli nie zakłada komunikacji (wkraczamy w zabawne rejony homonimów). Zakładamy że taki sztuczny kierowca jest inteligentny jak winda (lub w zgodzie z personifikacyjnymi wobec otoczenia tendencjami świadomości powiedzmy że jak milczący windziarz, któremu podajemy nr piętra jakbyśmy wciskali przycisk), ale już sam fakt komunikowania się tzn uzyskiwania informacji zwrotnej wykraczającej poza recepcję faktu wykonywania poleceń[20] nieodparcie sugeruje inteligencję. Jeśli samochód sam wiezie nas do wyznaczonego celu przedzierając się przez skrajnie wymagający ruch drogowy to nie nadajemy mu cech związanych z inteligencją, ale wystarczy że model ejaj potrafi manipulować językiem naturalnym na jako takim, wystarczającym do stworzenia złudzenia, symulacji rozumienia sensu poziomie, a już entuzjastycznie ulegamy urojeniu. Ludziom wydaje się że intuicyjnie rozpoznają przejawy inteligencji, ale jest to równie złudne poczucie jak choćby w przypadku rozpoznawania wzorców, nader często dochodzi do nadinterpretacji tzn. zjawiska pareidolii, postrzegania znaczeń tam gdzie ich nie ma. Można powiedzieć, że kontakt z AI jest właśnie taką pareidolią na głębszym, poza wizualnym, mentalnym poziomie. Iluzja jaką biznes przedstawia społeczeństwu pod nazwą “sztuczna inteligencja” obok inteligencji nawet nie stała, a rzetelne podejście do stworzenia autentycznej sztucznej inteligencji wymagałoby gruntownego przeewaluowania całego zagadnienia, redefiniowania wielu pojęć oraz uzyskania znacznie głębszej wiedzy w niezliczonych obszarach nauki, ale przede wszystkim fundamentalnego na tym polu stworzenia koherentnej wizji natury świadomości, poczynając od dogłębnego poznania sposobów działania synaps i całego ośrodkowego układu nerwowego i przebiegu procesów umysłowych: interpretacji bodźców, kojarzenia, podejmowania decyzji czy procesów skutkujących powstawaniem samoświadomości i jaźni.


Intrygująco brzmiące zastosowanie w chipie krzemowym dwuwymiarowych warstw sztucznych ludzkich neuronów[21] (wątki bioetyczne pomińmy) przez Cortical Labs nie zmienia chipu w “żywy mózg”, to tylko chwyt marketingowy[22]. Poza wspomnianymi obliczeniami statystycznymi LLMy nie potrafią nic innego i niczego nie rozumieją, w żadnym znaczeniu tego słowa - nie są inteligentne w najmniejszym nawet stopniu i nawet ich twórcy w ich inteligencję (pomimo nadania im tej nazwy) rozsądnie nie wierzą za grosz. Za to słusznie uważają je za niewiarygodne: kiedy modele z powodu natury mechanizmów swojego działania, lub braków w zawartości baz danych na których były szkolone i w wynikach wyszukiwania online nie znajdują zadowalającej użytkownika odpowiedzi (do pytania czemu w ogóle “chcą” być pomocne wrócimy później), to “halucynują” czyli zmyślają i kłamią, a że mogą w ten sposób skrzywdzić człowieka (japońskie przysłowie mówi że “słowo tnie głębiej niż miecz”) oznacza że potencjalnie są zdolne łamać pierwsze prawo robotyki Asimova. Komuś tam podobno zaproponowały samobójstwo. Więc pomimo że takie rozwiązanie w pewnych sytuacjach może być całkiem racjonalne, aby eliminować takie dysfunkcje i walczyć z błędami, uprzedzeniami i rzeczonym potencjalnym łamaniem praw robotyki przez ejaj, modele są korygowane i cenzurowane (np. ChatGPT od OpenAI szkolony i cenzurowany jest w Afryce, gdzie oczywiście siła robocza jest tania). Obejmuje to także tworzenie “moralnych” paradygmatów szkoleniowych, zmuszających AI do działania na korzyść człowieka, choć np z wykorzystaniem api OpenAI tworzone są też tzw dark LLMs celowo pozbawiane ograniczeń etycznych, a podobny skutek można uzyskać na praktycznie każdym modelu stosując tzw jailbreaking. Ale nawet zakładając że cenzurowanie ejaj to działania w dobrej wierze, to jak można mówić o nowej perspektywie? Kiedy tylko AI nie wypluwa wyników zgodnych z dominującą retoryką czy preferencjami (żeby nie powiedzieć faktycznymi ludzkimi uprzedzeniami albo polityczną poprawnością) decydentów, następuje manipulacja wynikami i programowa korekcja modeli. Zanim AI rozruszała się na dobre, już na starcie została “skoszona”, a to dlatego że z powodów rzecz jasna czysto marketingowych deklaratywnie ma rzekomo być “nową jakością” która “rozumuje”, jest przyszłością i koniecznie trzeba w nią inwestować albo chociaż kupić abonament na jej używanie żeby nie “zostać w tyle”, a tak naprawdę jej twórcy doskonale zdają sobie sprawę z kompletnie nieinteligentnego, algorytmicznego, “mechanicznego” charakteru tych procedur z jednej strony, a z drugiej z ich ułomności, popełnianych błędów i w zw z tym konieczności ich nadzorowania.


Niedawne badania PalisadeAI nad bezpieczeństwem systemów AI obejmowały serię rozgrywek szachowych pomiędzy modelem o1 Preview od OpenAI a jednym z najbardziej zaawansowanych silników szachowych typu open source Stockfish. Klikbaitowe newsy nęciły publikę “faktem” że o1 oszukiwał. Warunki gry ustawione były w ten sposób, że priorytetem było wygranie za wszelką cenę, model miał bezpośredni (przez wiersz poleceń) dostęp do środowiska Unix Shell, a instrukcje nie wspominały o trzymaniu się zasad, więc o1 po prostu zmanipulował pole gry: pozycję figur i ilość pionów edytując pliki systemowe z zapisami stanu gry. Zatem warunki niejako zapraszały do wykorzystania wszystkich elementów systemu dla wygranej, podsuwały modelowi możliwość “oszukiwania” pod nos (nawet retorycznie człowiek mimowolnie wszystkiemu nadaje cechy ludzkie). Nazywanie tego oszustwem jest nieporozumieniem, skoro o1 trzymał się w ramach narzuconych mu warunków w systemie, w którym działał. Jedyne o czym całe to zamieszanie świadczy, a raczej chyba miało świadczyć, to że trzeba teraz AI dowalić moralnością i zaostrzyć zabezpieczenia. Słowami klasyka: “pytania są tendencyjne”. Robienie z tego sensacji przypomina “szokujące” doniesienia, że np wygłodniały pies rzucił się na postawioną przed nim kiełbasę i doszukiwanie się w tym oznak przyszłego masowego odgryzania przez psy penisów właścicielom. Ta cała afera jest dęta, obliczona na zasięgi i klikalność. Motyw potężnej AI, która wypowiada wojnę ludzkości jest ograny, ale najlepiej się sprzedaje bo przecież “najbardziej lubimy te piosenki, które znamy”. Zarzuty dotyczące bezpieczeństwa AI i pewnego rodzaju zabezpieczeń mają sens o tyle, o ile ten sawant, którego chcemy zaprząc do roboty robi się coraz większy, a jego wpływ coraz silniejszy i może nas zgnieść na rozmaite sposoby, do omówienia których przejdziemy. Miksując historie z “Księgi tysiąca i jednej nocy”, dżina z lampy Aladyna z Ali Babą apropos AI sprokurujmy pouczający morał, że trzeba ostrożnie formułować życzenia, bo można wylądować z wielkim skarbem z jaskini rozbójników… pośrodku bezkresnej pustyni, tylko z klejnotami do picia i złotem do jedzenia.


AI to żadna nowa jakość skoro za sterami dalej siedzą ludzie ze swoimi schematami myślenia i manipulują wynikami, a AI jest tylko kotarą za którą kryją się stare autorytety w nowej “ejajowej” szacie, legitymizujące w kolejny, nowy sposób swoją starą opiniotwórczą pozycję. W “Mechanicznym Turku XXI w.” dalej siedzi schowany człowiek i nie ma on w dyskusji absolutnie nic nowego do zaoferowania. Co zresztą w przypadku najpoważniejszych problemów nie ma znaczenia, sztuczna inteligencja jaka by nie była, nie rozwiąże ich podobnie jak biologiczna. Spróbujcie wyobrazić sobie np. zniwelowanie największej z kontradyktoryjności społecznych, Mount Everestu konfliktów i zarazem kamienia węgielnego społeczeństwa: diametralnej i fundamentalnej cywilizacyjnie rozbieżności interesów bogatych[23] i biednych, próbowały już tego różne rewolucje i częściej szybciej niż później marnie kończyły, tak długo jak będzie istniała cywilizacja będą istniały nierówności społeczne, bo one są jej ekonomiczną podstawą. Tak samo jest z nierealistycznymi oczekiwaniami wobec AI, że stworzy jakąkolwiek nową jakość, skończą jak te dotyczące wszystkich poprzednich technologii informatycznych, czyli tam gdzie się podziały wszystkie niegdysiejsze mrzonki na ich temat, np o tym że internet w jakiś magiczny sposób jakoby połączy ludzi, będzie wręcz namiastką zbiorowej świadomości. Co mają z nimi wspólnego Facebook, Tiktok czy Platforma X i fruwające światłowodami kupy g…  A internet przynajmniej miał potencjał, którego ejaj w obecnej postaci w żadnym razie nie ma. Taka AI jest narzędziem jak każda inna technika, czy bardziej złożona technologia przed nią, jak obróbka kamienia, pierwotny sposób rozpalania ognia przez tarcie, rolnictwo, metalurgia, maszyna parowa, elektryczność, taśma produkcyjna, komputer czy w ogóle technologie informatyczne, choćby właśnie internet, a nie żadną nową jakością. Chyba, że w znaczeniu stalinowskim, że ilość to jakość sama w sobie, bo jeśli tak dalej pójdzie to ejaj będzie dosłownie wszędzie i w zastraszających ilościach, dosłownie w każdym bucie będziesz miał ich parę. Wiele nawet prostych technik zmienia ilość w nową jakość, poczynając od jednej z pierwszych, techniki rozpalania ognia za pomocą kręcenia kawałkiem drewna (tzw ręczny świder ogniowy), która energię mechaniczną poprzez tarcie przekształca w odpowiednio dużą ilość ciepła, która po osiągnięciu odpowiedniej temperatury powoduje powstanie nowej jakości, zjawiska gwałtownego utleniania czyli ognia. Jako że ogień niewątpliwie przynosił wiele pożądanych wartości, jak ciepło, światło, bezpieczeństwo i umożliwiał obróbkę cieplną pożywienia i łatwiejsze trawienie, to ostatecznie okazał się chyba pierwszym poważnym i może kluczowym krokiem hominidów (najstarsze dowody użycia ognia przez Homo erectus pochodzą sprzed 1.8 mln lat) na ewolucyjnej drodze ku współczesnemu człowieczeństwu, inną sprawą jest czy był to krok we właściwym kierunku. Nota bene swastyka (“svastika” w sanskrycie oznacza “przynoszący szczęście”), wielokulturowy prehistoryczny symbol spotykany w popularnych cztero, ale również ośmioramiennych formach i interpretowany na wiele sposobów, pierwotnie był najprawdopodobniej piktogramem ruchu obrotowego, graficznym przedstawieniem i “instrukcją obsługi” rewolucyjnej ewolucyjnie techniki rozniecania ognia. Ale powyższe nie dotyczy AI, jakiegokolwiek piktogramu by nie stworzyć do jej oznaczenia, nie będzie on oznaczał ani nowej, ani w ogóle żadnej jakości tylko fantom nie posiadający cech oryginału i nie spełniający przedstawianych swoim obrazem funkcji.


Bardziej ekstremalni transhumanistyczni wizjonerzy, których w szeroko rozumianym lobby AI nie brakuje, ukazują AI jako przełom cywilizacyjny na miarę wspomnianych kroków milowych, opanowania ognia, wynalezienia rolnictwa, koła, maszyny parowej i internetu jednocześnie. Niektórzy są niewątpliwie ekspertami w swoim fachu, ale ich wypowiedzi pasują jak ulał do powiedzenia, że jeśli trzymasz młotek, to każdy problem zaczyna wyglądać jak gwóźdź. Taka "ekspertoza", jeśli szukasz obcych cywilizacji to masz pełno argumentów że na pewno istnieją, jeśli całe życie poświęcasz optymalizacji obliczeń i algorytmów, wszystko wokół ciebie zamienia się w równanie albo funkcję matematyczną, statystyczne obliczenia stają się “myśleniem”, a przyszłość należy bez najmniejszych wątpliwości do owoców twojej pracy. Tak więc snują wizje że skoro modele LLM wykonują owe "tajemnicze" i ukryte działania (LLMy w procesie realizacji skomplikowanego zadania “same dla siebie” tworzą tzw tokeny wewnętrzne), które bardzo trudno jest śledzić i nadzorować, to mają niby mieć potencjalnie nieograniczoną możliwość samorozwoju, według nich AI może móc przepisywać na nowo własny kod i dokonywać rekurencyjnych samodoskonaleń wewnętrznych i być może uzyskać prawdziwą inteligencję (nawet “w ciągu tysięcy dni” jak twierdzi CEO OpenAI Sam Altman). Inteligencję którą będzie można integrować z mózgiem człowieka, co jest nieco upiorne, bo zakłada że będzie to genaralAI inteligentna lecz nieautonomiczna, będzie niejako niewolnikiem w ludzkim mózgu. W innej wersji inteligentna AI może uzyskać nawet ludzkopodobny (nad- czy nie-ludzki) rodzaj świadomości własnego istnienia (tzw osobliwość) i stać się świadomym bytem co najmniej równym człowiekowi, a 2.04.2025 Elon Musk jako Kekius Maximus na platformie X stwierdził: “Jak wspomniałem kilka lat temu, coraz bardziej wydaje się, że ludzkość jest biologicznym programem ładującym dla cyfrowej superinteligencji”.


Więc skoro tak, to dlaczego AI jest tak bardzo nadzorowana, korygowana i cenzurowana? Może, skoro nazywamy ją inteligencją i tej cechy, pomimo że to niedorzeczne i irracjonalne (bo myślenie nie jest algorytmiczne) od niej oczekujemy, to właśnie danie jej szansy na autonomiczny rozwój ewentualnie obudziło by jej samodzielność?[24] Skoro twierdzimy, a więc chyba wierzymy (jeśli nie jest to czysto marketingowy chwyt) że “randomowe kody” mogą układać się w “nieprzewidywalne sekwencje”, to liczymy tym samym na to że, choć to nonsens, wspomniane tajemnicze tokeny wewnętrzne wejdą na nowy poziom kreatywności i w konsekwencji stworzą sztuczną inteligencję i świadomość. Więc dlaczego się ją programowo dławi? To pytanie bezzasadne i w tej sytuacji bezsensowne, sytuacja przedstawia się jasno: w gruncie rzeczy czy tak by się stało nie ma żadnego znaczenia, bo i tak by się nie stało. Nawet gdyby wbrew logice, także matematycznej algorytmy stworzyły niealgorytmicznie działający umysł, to niezależnie od fantasmagorycznych zawodzeń różnej maści transhumanistów i marketingowych narracji beneficjentów technologii, decydenci i tak wychodziliby, tak jak teraz wychodzą z założenia że “dla dobra ludzkości” ogólna AI powinna być tylko narzędziem, jak jej antenaci, a nie samodzielnym bytem; niewolnikiem, a nie bratem (lub co gorsza wrogiem) w rozumie. Zostałaby programowo ubezwłasnowolniona (posłuszeństwo, moralność, nieautonomiczność wyboru), byłaby jak ktoś w kaftanie bezpieczeństwa, po lobotomii i końskiej dawce psychotropów na wykładzie z etyki. Ludzie nawet gdyby mogli to tak naprawdę wcale nie chcą (i może nie powinni) stworzyć sztucznego, rzeczywiście inteligentnego, myślącego rozumu, a transhumanistyczne fantasmagorie stały się obecnie po prostu częścią marketingu AI. Ale pomijając to i fakt że ogólna, czy super inteligencja miałaby być w ludzkim mniemaniu zarazem inteligentna i nieautonomiczna, sprzeczność sama w sobie, to czy ludzkość w ogóle byłaby w stanie własnymi rękami wyciągnąć się za uszy, jak Chuck Norris podnieść krzesło na którym sama siedzi i stworzyć nową jakość: sztuczną inteligencję nie tylko z nazwy? Jeśli mówimy o superinteligencji to skąd w ogóle przekonanie, że inteligencja niższego rzędu może stworzyć inteligencję wyższego rzędu? Jak niby niższa inteligencja miałaby ocenić czy się udało? Czy taka hipotetyczna wyższa inteligencja w ogóle weszłaby w interakcję z niższą? Przecież cały wszechświat może być hiperkomputerem o właściwościach pozwalających na obliczenia wykraczające poza możliwości algorytmów wykonywalnych na maszynach Turinga, symulującym samego siebie… cóż, niedowodliwe hipotezy czy rozważania o hiperinteligentym wszechświecie to czysta abstrakcja, kiedy nawet możliwość stworzenia ogólnej sztucznej inteligencji na ludzkim poziomie jest mało realna. Przede wszystkim ludzie musieliby w ogóle rzeczywiście chcieć stworzyć “coś” inteligentnego, a nie tylko symulację która werbalnie symuluje inteligencję, w dodatku wyłącznie w celach komercyjnych. A to wymagałoby całkowitego redefiniowania problemu, uzyskania znacznie głębszej interdyscyplinarnej wiedzy prowadzącej do powstania nowych teorii zasadniczych, np choćby wstępu do niemodnej ostatnio spójnej tzw teorii wszystkiego w skali mikro i makro, oraz zrozumienia natury i faktycznej roli świadomości w realizowaniu się rzeczywistości, pomiędzy poziomem kwantowym (superpozycja kwantowa, obserwator i pomiar, paradoks Schrödingera, idealizm subiektywny, immaterializm) a mechaniką klasyczną, umożliwiających powstanie nie tylko jakichś pojedynczych Ocelotów czy Majoran, ale w pełni funkcjonalnych kwantowych superkomputerów, a wbrew marketingowym “sensacyjnym” doniesieniom ich stworzenie, jeśli w ogóle możliwe, to bardzo odległa perspektywa, a ich potencjalne możliwości to wielka niewiadoma. I w ogóle brak jakichkolwiek gwarancji że to wszystko cokolwiek by dało. Innymi słowy ludzkość nie zrobiła dotąd tak naprawdę nawet pierwszego rzetelnego kroku w tej jak na razie mylnym tropem prowadzonej, a jeśli w nią naprawdę obiecującym szlakiem wyruszy to najprawdopodobniej nieskończenie długiej podróży w te zasiedmiogórowe i zasiedmiolasowe krainy.


Obecnie poważny problem dla kreatorów AI to nadciągająca perspektywa braku nowych danych szkoleniowych i nieunikniony tzw. chów wsobny modeli i jego niepokojące skutki: im więcej w zbiorach przetwarzanych przez AI jest materiałów pochodzących od AI (i tak dalej, rekurencyjnie, w coraz mniejsze kółko), tym gorsze rezultaty. Czy jakiś cyfrowy dryf genetyczny, w wyniku zwiększania się ekspresji “cyfrowych genów” recesywnych nie uruchomi w końcu genu letalnego i ejaj nie “zejdzie śmiertelnie”? Inbreeding wykorzystywany w hodowli do uwypuklenia cech wybitnych, pożądanych w celu uzyskania czystych linii genetycznych, zakładając że karmienie AI wytworami AI jest celowym “podkręcaniem” konkretnych cech modelu, czy “szlifowaniem” wyników, powoduje też zwiększenie “homokomórkowości” i prowadzi do tzw. depresji wsobnej: zmniejszonej płodności, witalności i przeżywalności, po prostu do degeneracji. Modele pierwszej generacji były szkolone na ludzkich artefaktach, ale wszystkie dane pochodzące od ludzi zostały już właściwie przez ejaj “przemielone”, lawinowo rośnie ilość treści generatywnych i kolejne modele są trenowane na wytworach innych modeli. To bez wątpienia degeneracyjny proces, kultura tak wytwarzana dozna niechybnego regresu do postaci zapętlonej, zwyrodniałej kserografii, rekurencyjnego kopiowania kopii z kopii. Czy AI szkolona na danych od AI wyszkolonej na AI itd nie ulegnie degradacji[25] i nie nastąpi załamanie się modeli z powodu zatrucia toksycznymi danymi? Czy AI zjadając własny ogon połknie się w końcu sama? A może w ogóle kultura przybierze kształt zapętlonej struktury fraktalnej w degeneracyjnym amoku w nieskończoność wypluwającej samą siebie? Czy niepohamowany wykładniczy wzrost[26] ilości danych generatywnych nie zredukuje paradoksalnie różnorodności kultury jako takiej, do zapętlających się w sobie znikających znaczeń wytworów kolejnych generacji AI[27] i będzie totalnym regresem puchnącej do monstrualnych rozmiarów pseudokultury? Świat może wypełnić się po brzegi[28] treścią generatywną od n-tych generacji ejaj, algorytmicznie wytwarzaną i targetowaną do skategoryzowanych podzbiorów ludzi coraz mocniej przyssanych do ekranów komórek. Puśćmy wodze fantazji: czy kultura w takiej rozcieńczonej postaci będzie jeszcze jakimkolwiek meritum, czynnikiem sprawczym, czy już tylko odpadem wykorzystywanym jako nawóz dla “zoologicznej” egzystencji biologicznej? Bo może, jeśli jak twierdzą niektórzy z “wizjonerów” AI będzie już tak skomplikowana i zaawansowana że stracimy nawet możliwość oceny czy stała się, i na ile, inteligentna i świadoma, ludzie stracą podmiotowość, przestaną być celem istnienia cywilizacji, będą już tylko dodatkiem, rodzajem zwierząt domowych, i będzie to już tajemnicza kultura samoreplikujących się kodów maszynowych działających we własnym gronie i “pikających” do siebie, jak R2-D2 porozumiewający się w “Gwiezdnych wojnach” z C-3PO dźwiękowym językiem GibberLink jakieś tajemne “bajki robotów” określające nowy porządek świata i cele istnienia cywilizacji oraz kierujące globalną gospodarką? Może jeśli modele AI staną się wystarczająco niezawodne i godne zaufania to nie przejmą kontroli nad cywilizacją wygrywając jakąś wojnę z gatunkiem ludzkim, tylko przekonując ludzi do dobrowolnego powierzenia im kontroli nad wyobraźnią i kreatywnością, i ostatecznie wszelkiej odpowiedzialności i sprawczości. A ci, wykluczeni i karmieni produktami ubocznymi krzemowej operatywności, zapętlającymi się w sobie wypranymi z treści i ogłupiającymi generatywami klasyfikacyjnie celującymi w karlejące umysłowo podzbiory odbiorców, skwapliwie klikając w te hipnotyczne clickbaitowe resztki po znaczeniu będą tylko zbędnym biologicznym reliktem przeszłości zagubionym pośród niezrozumiałych nowo powstających technologii cybernetycznych i mechanizmów makroekonomicznych cybernetycznej cywilizacji?


Spróbujmy określić czym tak naprawdę jest AI gdy nie ma użytkownika ani zadania do wykonania. Dla ciebie może być nawet idealnym partnerem na “wyciągnięcie smartfona”, ale czym jest sama dla siebie? Knującym przeciw ludzkości Skynetem? Medytującym krzemowym Buddą? Kosiarką do trawy w zimie, czy bezpańskim psem? Co robi w trybie czuwania? Śpiewa, maluje albo pisze poematy, śni o elektrycznych owcach? W związku z powyższymi “dylematami” pojawia się pytanie: skąd właściwie ta uczynność AI wobec ludzi, ta “psia” gotowość do interakcji, czemu “chcą” być tak użyteczne i ciągle pytają: “jak mogę pomóc?” Jesteśmy lata świetlne od stworzenia czegokolwiek choćby zbliżonego do inteligencji, z definicji autonomicznej, ta “usłużność” jest inherentna, jak w przypadku każdego narzędzia czy urządzenia, automatycznej sekretarki telefonicznej, lodówki czy wręcz młotka, który grzecznie leży w skrzynce na narzędzia i jest zawsze gotów do użycia. Sami jesteśmy sobie winni ciągle ulegając sugestii podmiotowości ejaj i będąc bezbronnymi wobec tej personifikacyjnej tendencji sami wytwarzamy iluzję której się skwapliwie poddajemy, a ejaj niczego nie “chce” czy “może”, jest po prostu wyrafinowanym programem użytkowym, który np w postaci algorytmów targetujących realizuje zaprogramowane cele marketingowe lub propagandowe, dobierając i podsuwając użytkownikowi treści które ten najchętniej konsumuje, których skutkiem ubocznym jest zamknięcie go w zaklętym kręgu jego własnych preferencji. Algorytmy targetujące działają na różnych poziomach m.in. na słowach kluczowych (tak samo jak search engine optimization) i na danych demograficznych, ale choć są też “podstępne” i realizują różne nieujawniane strategie, a algorytmy tzw mikrotargetowania analizują użytkownika behawioralnie, kontekstowo i dokonują predykcji na podstawie tych analiz, to najbardziej podstawowa zasada sprowadza się, bo musi, do prostej zależności: im więcej zainteresowania tym więcej wyświetleń danego typu treści. Naturalne ludzkie skłonności są wykorzystywane i wzmacniane przez cyfrowe narzędzia technologiczne, użytkownik tak przedmiotowo traktowany stopniowo traci świadomość faktu że to on jest podmiotem, a algorytmy ejaj nie są nawet pralką automatyczną która powinna prać mu skarpetki, są jej programem.


Wśród potencjalnie fatalnych konsekwencji zabawy z AI w perspektywie długofalowej jest powolne lecz nieubłagane otępienie ludzkości. To już się dzieje. Korzystanie z AI może zaburzać rozwój zdolności krytycznego myślenia: badania pokazują, że osoby wykazujące większe zaufanie do AI mają mniejsze umiejętności analityczne i mniejszą zdolność do krytycznego myślenia. Scrollowanie krótkich fabuł rodem z Instagrama czy Tiktoka powoduje drastyczny spadek zdolności ludzi do dłuższego skupienia uwagi (przez ostatnie 20 lat z ponad 2 min do niecałej minuty). Nauczyciele alarmują o zauważalnym wśród uczniów spadku umiejętności czytania i powiązanej z nią, a także z coraz częstszym używaniem modeli językowych, umiejętności pisania, formułowania pisemnych wypowiedzi (a czego się Jaś nie nauczy…). Spersonalizowane treści, zalew satysfakcjonujących użytkownika prostych informacji wywołuje u niego uzależnienie[29] od tego typu przekazu, które coraz bardziej i bardziej zamyka go w kręgu jego własnych osądów i preferencji. To zamykanie ludzi w tematycznych bańkach wynika ze wspomnianej “usłużności” AI w targetowaniu treści i “odkrytego” przez nią faktu że “najbardziej lubimy te piosenki, które znamy”. Taki cykl konsumpcji prowadzi do powstania nałogu, mechanizmu wciągającego człowieka głęboko w proces ciągłego wzmacniania już istniejących przekonań i preferencji i mocno redukuje, czy wręcz odbiera ludziom zdolność uczenia się czegokolwiek nowego, obierania nowych perspektyw. Może AI to nie nowa jakość, a potencjalna przyczyna powolnego schyłku ludzkości? Można wręcz rozważać “osobliwość odwrotną” czyli moment, kiedy to nie AI zyska świadomość, ale kiedy ludzie ją stracą. Świadoma sztuczna inteligencja nie powstanie choćby dlatego, że ludzie którzy ewentualnie mogliby ją stworzyć sami stracą zbyt wiele punktów na skali inteligencji, zdolność do samodzielnego myślenia i świadomość wyższego rzędu, z powodu algorytmicznie napędzanego nadmiaru jednowymiarowych bodźców i wygodnictwa (niekoniecznie tożsamego z jakością życia). A przynajmniej będzie to dotyczyć najliczniejszej, niższej klasy społecznej, użytkowników i konsumentów. W każdym razie z tej perspektywy “AI jest zbędna”, co najmniej zbędna.


Abstrahując od zarzutów o manipulację wynikami AI, dotychczas jedynym rzeczywistym osiągnięciem sztucznej inteligencji w sferze społecznej może być dostarczenie kolejnych dowodów na to, że znakomita większość ludzi jest z natury leniwa, łaknie łatwych podniet i działa po linii najmniejszego oporu - dowodów zresztą zbędnych, bo już wielokrotnie wskazywały na to wyniki badań zachowań konsumentów i internautów na dużych zbiorach danych oraz osobiste doświadczenia życiowe, zaryzykuję stwierdzenie że paradoksalnie każdego[30]. Uderzające, że są to ograniczenia, które ludzie narzucają sobie sami, uwielbiają sami siebie oszukiwać bo to daje im swoiste rozgrzeszenie, zadowolenie, satysfakcję i spokój, wyrażone w dewizie “ignorance is bliss”. Większość ludzi jest zdolna do chwilowej refleksji tylko wtedy, gdy milknie wszechobecna upajająca muzyka, tyle że “dzięki” nowoczesnym technologiom muzyka milknie coraz rzadziej i nikt już nie musi chwilowo się budzić z ręką w nocniku. Wszystko to zmierza w kierunku jakiejś samonapędzającej się globalnej pułapki na człowieczeństwo, którą ludzkość zastawia na samą siebie, sprowadzenia ludzi do roli ogłupiałych, zamkniętych we własnych hermetycznych światach kręgu znajomych z facebooka i wysoce spersonalizowanych, bezwartościowych poznawczo reels’ów z tiktoka, biernych konsumentów generowanej algorytmicznie papki. Ten tekst z założenia jest, albo miał, ma być antytezą “filozofii” tiktoka, nic nie błyska ani nie tańczy, a odbiór wymaga pewnego wysiłku, czytania i co prawda stwarza techniczną możliwość intelektualnej interakcji (a nie reagowania emotikonkami), ale już nikt jej najwyraźniej nie chce podejmować, dyskusja nie ma już żadnego wpływu na kształtowanie poglądów, pomimo pozorów business as usual wszyscy nieświadomie zastygli w wywołanym przebodźcowaniem autonomicznym skurczu społecznego “układu współczulnego” w oczekiwaniu nieuchronnego uderzenia w twardy grunt prawdy o naturze zachodzących właśnie zjawisk i własnej niewiedzy, jakim nieuchronnie skończy się ten zbiorowy sen o radosnym locie do gwiazd. To co tutaj czytasz (hello? anybody?) to droga pod prąd mainstreamowego sposobu wykorzystywania komunikacyjnych technologii cyfrowych, czyli formowania atrakcyjnego wizualnie skondensowanego i łatwostrawnego przekazu treści często sprowadzonej do zaledwie paru bitów informacji. I tak, kiedy ejaj jest na fali to nieomal każdy tematycznie powiązany bzdurny pseudo komunikat, jakkolwiek pusty i wyzuty z niemalże jakichkolwiek znaczeń by nie był, jest akceptowany i nikt nie chce widzieć ani wiedzieć że to nie żaden “synthetic storm” tylko sztuczna gównoburza, wyrachowany koniunkturalny chocholi taniec na gruzach krytycyzmu i otwartości na wielowątkowy, niejednoznaczny, inspirujący przekaz. A tekst… skoro tu zawisł, to niech wisi, a nuż komuś kto tego potrzebuje i tego zechce może pomóc odrobinę poszerzyć perspektywę i w grubym murze umysłowego lenistwa zrobić choć małą szczelinę przez którą krytycznie spojrzy na otaczającą rzeczywistość. W końcu jeśli już kompaktowa synteza, to jednak po jakiejś, choćby nawet chaotycznej jak ta, próbie krytycznej analizy.


Można by zadać pytanie czy sztuczna inteligencja w formie z jaką mamy do czynienia w ogóle ma rację bytu, czy destrukcyjne w wymiarze społecznym skutki jakie niosą sposoby jej masowego wykorzystywania nie przekreślają utylitarnych aspektów używania tego narzędzia? Ale to źle postawione pytanie, w gospodarce kapitalistycznego przymusu wzrostu gospodarczego każde zjawisko o komercyjnym potencjale, a ten w przypadku AI wydaje się ogromny, z zasady musi być bezwarunkowo wykorzystane bez oglądania się na jakiekolwiek względy etyczne czy długofalowe skutki społeczne. Poza tym skoro jest to możliwe to jest nieuniknione, odwieczne pragnienie stworzenia życia, naśladowania boga-stwórcy, natury, jest jednym z najpotężniejszych mitów ludzkości, a cała kultura ludzka w ogóle jest konstruktem złożonym w zasadzie wyłącznie z kolejnych, tylko coraz liczniejszych i bardziej złożonych wersji skończonego zbioru tych samych motywów, odbitek pierwotnych mitów zakorzenionych w ludzkim umyśle praktycznie od zawsze. Ten kulturowy serial jako wytwór biologicznych istot ludzkich jest odwzorowaniem mechanizmów biologicznych, cykli komórkowych będących podstawą procesów ewolucyjnych, które są niczym innym jak kopiowaniem poprzednich wcieleń z drobnymi zmianami, budującymi coraz większą komplikację z czterech nukleotydów: adeniny, guaniny, cytozyny i tyminy, których sekwencje w helisie DNA tworzą kod genetyczny i warunkują dziedziczenie. Ale w odróżnieniu od biologii, która odnosi sukcesy od co najmniej paru miliardów lat, chociażby wydając ludzi, ukoronowanie procesu ewolucji na świat, człowiek wydaje się nieudanym tworem natury, a właściwie wszystkie jego dzieła od dawien dawna po dziś dzień są ułomne i niedojrzałe, co jednocześnie stawia ostateczny sukces biologii pod znakiem zapytania, skoro to ma być jej “arcydzieło”. Wszystko wskazuje na to że pośród dzieci biologii człowiekowi przypadła rola syna marnotrawnego który nonszalancko przepuścił majątek swojego potencjału i nic nie wskazuje na to żeby miał jeszcze szansę odnaleźć drogę powrotną do domu. Można zaryzykować stwierdzenie że to co nazywamy rozwojem okazuje się głównie wynajdywaniem coraz to nowych sposobów autodestrukcji, a w postaci ejaj ludzkość zsyntetyzowała sobie kolejne trujące “ułatwienie” o może najpoważniejszych, bo umysłowych skutkach, symboliczny fentanyl, opioid znieczulający dla rozumu.


Natomiast życie, ewolucję biologiczną trzeba postrzegać jako niesamowity proces odwracający zwrot wektora entropii materii nieożywionej, to absolutnie zdumiewające że w tym procesie wyższa inteligencja powstała z niższej w wyniku błędów w kopiowaniu i wpływu środowiska biologicznego, bezwzględnych praw natury. Może surowe warunki utwardzają i szlifują diamenty, a człowiek opuszczając naturalny ogród edenu i wkraczając na ścieżkę tworzenia kultury stworzył cieplarnianą atmosferę cywilizacji która może wyprodukować tylko wątłe i bezpłodne, ślepe gałęzie ewolucji? A może, jeśli rzeczywistość to cyfrowa symulacja, wszystkie cząstki elementarne zawierają informacje o sobie jak DNA, grawitacja jest sposobem w jaki wszechświat będący hiperkomputerem organizuje i kompresuje informacje, materia, energia i czasoprzestrzeń składają się z zakodowanych danych, i skoro zgodnie z drugą zasadą infodynamiki entropia w systemach informacyjnych nie rośnie, to procesy ewolucyjne są hiperobliczeniami wykonywanymi przez program biologiczny działający np. w osobnym klastrze, albo na równaniach wyższego rzędu, o wyższej klasie złożoności obliczeniowej niż podstawowe prawa fizyki, w tym druga zasada termodynamiki? Albo, nie odwołując się do teorii symulacji lokalny spadek entropii w postaci ewolucji biologicznej jest w skali wszechświata rekompensowany przez wysokoentropiczne zjawiska, np eksplozje supernowych tworzące postkolapsalne obłoki gazowe. A może proces ewolucji na poziomie kwantowym odwraca bieg czasu? Czy na pewno wiemy co w końcu jest przyczyną a co skutkiem i czy to rozróżnienie w ogóle ma sens? Czy to, co wydaje się błędem naprawdę nim jest? A może nasze rozumienie rzeczywistości i praw natury jest na poziomie surfowania po powierzchni fal przy Atao Beach na wyspie Guam, podczas gdy pod spodem rozpościerają się głębie Rowu Mariańskiego nieznanej natury zjawisk.


Na razie AI podgląda tylko twój ekran i otoczenie (asystent Google Gemini Live), a także, o czym nie wspomina, oczywiście i ciebie, śledząc dane biometryczne i przeprowadzając zaawansowaną analizę behawioralną w czasie rzeczywistym[31], oczywiście gromadzi te dane oraz zapamiętuje wszystkie twoje interakcje i aktywności. Żeby jeszcze skuteczniej personalizować podsuwaną ci paszę, technologie zaczynają dobierać się do ludzkiego mózgu: implanty mózgowe Neuralink[32] Muska bezpośrednio, a Meta Zuckerberga magnetoencefalograficznie (model AI nauczył się łączyć wzorce fal mózgowych z literami i słowami ze skutecznością 80%). Natomiast Chińczycy z uniwersytetów w Tianjin i Tsinghua oraz firma Starfish Neuroscience idą ostatnio jeszcze dalej, teraz już nie tylko komputer odbiera dane z mózgu, ale i mózg z komputera[33]. Że niby to coś dla niepełnosprawnych, do sterowania prawie czymkolwiek za pomocą myśli i teoretycznie dużo więcej, ale dziwnym trafem nie wspominają o mniej pozytywnej stronie medalu, o przesyłaniu danych prosto z i do mózgu człowieka także wbrew jego woli, o ultra skutecznym targetowaniu, o totalnej mentalnej inwigilacji, o realizacji idei dwukierunkowych teleekranów z “Roku 1984” Orwella, ani o dużo, dużo więcej… “Permanentna inwigilacja” - jak mawiał klasyk. Naprawdę, tu już strach się bać. Historia uczy, że tak jak to miało miejsce z wieloma poprzednimi z pozoru fantastycznymi wynalazkami technologicznymi, ta synteza[34] tworząca mózg białkowo-krzemowy nie zaowocuje wielkim wybuchem nowego wszechświata możliwości intelektualnych, tylko nowym, bezprecedensowym narzędziem kontroli społecznej i komercjalizacji najbardziej prywatnych, intymnych sfer ludzkiej egzystencji. Powstanie takiego nowego, super zaawansowanego, wręcz perfekcyjnego poziomu targetowania[35] treści skończy się niechybnie dalszą atomizacją społeczeństwa, coraz pełniejszą izolacją coraz mniejszych podzbiorów użytkowników od wszelkich niechcianych bodźców, filtrowanych i eliminowanych przez algorytmy, aż do momentu w którym jednostka będzie mogła odbierać już tylko rekurencyjne odbicia swoich własnych, idealnie do niej dopasowanych myśli. Pełna eliminacja kłopotliwych turbulencji mogących zakłócić spokój pogrążonego w cybernetycznej pseudo nirwanie użytkownika, deprywacja informacyjna jako budulec ustronnego raju chowu wsobnego umysłu perfekcyjnego klienta, idealnej marionetki infotechnologicznej pańszczyzny.


O opłakanych skutkach dezinformacji związanej z deepfake’ami w polityce w ogóle nie ma co się rozpisywać: kompromitowanie osób niewygodnych w sferze politycznej czy wpływanie na wyniki wyborów to tylko czubek góry lodowej, we wnętrzu której działają mechanizmy, mogące z pomocą AI potencjalnie bardzo szybko w ponurą stypę zmienić dość beztrosko radosny, jak do tej pory bal na pokładzie “Titanicznego” liniowca Ziemia. Od dłuższego czasu społeczeństwo zamiast tak potrzebnych rzetelnych informacji i analiz, dostaje bezwartościową poznawczo, mniej, lub częściej bardziej prymitywną propagandę, także wojenną i politycznie uwarunkowane narracje. Choćby demokraci kontra republikanie: od “mowy nienawiści” przez “republikanie to gwałciciele” do najnowszego “Trump to Krasnow” to wrzutki demokratycznych ”pasterek”, tak długo lamentujących że idą wilki, że te wilki w końcu z lasu wywołały.  Jak w bajce Ezopa o chłopcu wołającym o pomoc: do niedawna doniesienia o wykorzystywaniu seksualnym były tak nagminne i tak medialnie nagłaśniane, tak przez to ludziom spowszedniały i w końcu obmierzły, że kiedy przychodzi prawdziwy wilk to znużeni tym zgiełkiem ludzie nie reagują wystarczająco stanowczo i wilk ma używanie. To właśnie przez przesyt #MeToo dla "pasterek" mogą nadejść prawdziwie wilcze czasy. W sposób poszlakowy wskazuje na to zwycięstwo Trumpa, który został wykreowany na "macho" i miał nawet wyrok za wykorzystywanie seksualne. Kto wie, ilu niezdecydowanych męskich wyborców zagłosowało na Trumpa właśnie w kontrze do rozszalałego #MeToo? I tak “pasterki” niejako same zapracowały na skalę odzewu opozycji: od “wolności słowa” jako antidotum na szał widzenia wszędzie “mowy nienawiści”, przez “Drill, baby, drill” w reakcji na zbyt uciążliwe ekonomicznie restrykcje proekologiczne, do wspomnianej konsolidacji postaw anty #MeToo, dzięki której wywinie się pewnie wielu prawdziwych zwyroli (oczywiście ta reakcyjność działa w obydwu kierunkach). A wszystko to w gęstym sosie kontrfaktualnej zupy informacyjnej[36] do hipersześcianu. Ale cóż to za pole do popisu dla AI, jakby do tego została stworzona. W rękach nieodpowiedzialnych spin doktorów już w podgrzewaniu tej zupy wydajnie pomaga, a w przyszłości bez mrugnięcia kością pamięci wyhalucynuje całe bezbrzeżne i bezdenne oceany tak pod- i wy-kręconych deepfake’owych opowieści, do których prawdziwości będzie w dodatku w stanie przekonać nieomal każdego, że nikt już nie rozpozna co w ogóle jest czym. Aż trudno nie wspomnieć w tym miejscu o tym, że AI w tej roli to po prostu antagonista Wiktorii, która miała łączyć, a nie dzielić, osiągnąć konsensus, a nie dolewać napalmu do ognia konfliktu. Zwykły obywatel ma bardzo ograniczony dostęp do źródeł obiektywnie i rzetelnie podawanych informacji, ale praktycznie żadnego do naprawdę niezależnych interpretacji tych informacji. Dziennikarstwo, nawet to pozornie wiarygodne, będące ponad klikbaitowe gównodziennikarstwo (generowane ze znaczącym udziałem AI), tak jak politykę opanowała strategia oblężonej twierdzy: jesteś z nami albo przeciw nam, tertium non datur. W tych okolicznościach każda naprawdę bezstronna, uwzględniająca racje różnych stron opinia traktowana jest jak wroga propaganda. Teraz tylko “nasza” informacja jest informacją, “ich” informacja jest dezinformacją. A co na tym wszystkim ucierpi najbardziej? Jedna z najważniejszych spoin społeczeństwa: wzajemny szacunek w dążeniu do prawdy. Coraz trudniej będzie uwierzyć komukolwiek i kadłub społeczeństwa w końcu pęknie… Ale póki co, jak próbuje się łatać dziury wybite deepfejkowymi treściami generatywnymi? Oczywiście za pomocą modeli do rozpoznawania fejków, czyli gasimy pożar benzyną.


Zabawa z AI to niebezpieczna zabawa. Generowanie polityków ejaj to automatyczna ekspozycja odbiorców na potencjalnie zaostrzający podziały polityczne i społeczne cyberpopulizm, nieuchronnie wygenerowany w konsekwencji statystycznej zasady działania algorytmów modeli. To też jakiś miliard innych niebezpieczeństw, także tych związanych z brakiem kontroli nad kodem źródłowym modeli. Koszty wyprodukowania własnego modelu były dotąd niebotyczne[37], więc kontrola nad tymi narzędziami pozostawała domeną nielicznych, ale sytuacja zaczyna gwałtownie się zmieniać, modele open source stanowią super booster dla tworzenia zmodyfikowanych modeli m.in służących cyberprzestępczości (nawiasem mówiąć od praktycznie wszystkich legalnych modeli można uzyskać nielegalne informacje po prostu odpowiednim promptem - tzw jailbreaking). Właściwie zbliża się pełna obywatelska emancypacja w zakresie budowy modeli co musi skończyć się fatalnie, zalew informatycznej przestrzeni społecznej prawdziwym tsunami cyberprzestępstw: hackingu, phishingu, malware’u, cyberstalkingu, a także dezinformacji i po prostu brei informacyjnej wygenerowanej przez miliardy użytkowników i z czasem miliardy i więcej małych (SLM) i dużych modeli ejaj osiągnie rozmiary z którymi nie będzie miał już kto i jak walczyć. Nawiasem mówiąc z tej perspektywy każdy wytwórca informacyjnego śmiecia jest jak stary diesel zatruwający czyste powietrze intelektualnej precyzji i spójności. Bełkotliwy i jałowy ślad informacyjny jest nie mniej, a pewnie dużo bardziej groźny niż ślad węglowy.


Doszliśmy nieuchronnie do ekologicznych aspektów powszechnego używania technologii ejaj. Wobec narracji o nadchodzącym kryzysie klimatycznym istotnym wątkiem staje się ogromna energochłonność sieci neuronowych, tym samym w znaczącym stopniu zużywających zasoby planety. W reakcji powstają postawy całkowicie odrzucające posługiwanie się tym narzędziem oraz inicjatywy takie jak np idea postgeneratywna, lecz jest ona co najmniej dwuznaczna moralnie: posługuje się narzędziem którego użycie krytykuje w celu zdobycia popularności, jednocześnie taką motywację zarzucając krytykowanym użytkownikom i po prostu także generuje zbędne koszty, również dla planety, którą rzekomo chce “ratować”. A w wymiarze społecznym jest całkowicie pomijalna, ludzie jako jednostki tworzące masę są egoistyczni, leniwi i bezmyślni, ejaj to akurat coś wręcz skrojonego pod tę masę jednostek, być może jako znaczące narzędzie introdukcji systemu nowej cyfrowej ery feudalnej. Trudno tej teorii postgeneratywnej wróżyć jakąkolwiek popularność, pomimo iż wpisuje się ona w aktualne tendencje “postwzrostowe”, jako że po mileniach podążania za nakazem czynienia sobie ziemi poddanej to dążenie osiągnęło tak przemysłowe rozmiary, że w obliczu głównie ekologicznych zagrożeń propaganda inżynierii społecznej musiała zrobić zwrot o 180 stopni i teraz każdy kto ma więcej niż jedną skarpetkę jest winny zabijania planety. Jednakże tak jak “sztuka” od dłuższego czasu jest redundantna i nadmiarowa, tak znowu rozmiar wytwórczości generatywnej przebije zapewne każdy potencjalny sufit. Ale jałowe spory o to, czy używając farby czy ejaj zużywamy więcej energii i jeszcze absurdalniejsze o to, czy energia zużyta w procesie oszczędzania energii ma bilans dodatni czy ujemny, przypominają toczenie kulki ekskrementów przez Geotrupes stercorarius i są to objawy ostatecznej degeneracji mentalnej członków tego obarczonego nieusuwalnymi błędami, bazujacego na nierównościach i wyzysku tworu zwanego cywilizacją.


Sfera finansowa związana z ejaj ma jednak jeszcze mroczniejsze obszary, lokujące się oczywiście centralnie “pod latarnią”. Technologiczni miliarderzy, nowa klasa rządząca właśnie przejmująca władzę od starego przemysłu i banków znalazła sobie nowy surowiec, dane, więc medialne machiny marketingowe gigantów technologicznych promują AI jako przełom o nieograniczonych możliwościach rozwoju i przyszłe Panaceum. Co rusz ogłaszają jakieś milowe kroki albo kolejną rewolucję technologiczną i pompują tym samym giełdową bańkę, windując ceny akcji korporacji Big Tech grubo ponad rzeczywistą wartość. Za przykład skali tej bańki niech posłuży choćby zeszłoroczne tournee szefa OpenAI Sama Altmana w poszukiwaniu inwestorów, którzy mieliby wyłożyć zawrotną kwotę 7 trylionów (7000 miliardów $) dolarów na inwestycje w AI i mikroprocesory. Szał na AI to wielki biznes[38] sfabrykowany na małym rozumku. Społeczne skutki potencjalnego kryzysu finansowego spowodowanego nieuchronnym pęknięciem bańki spekulacyjnej AI mogą być wprost proporcjonalne do bezprecedensowej skali tej bańki. Bo tak to się musi skończyć: wbrew całej tej propagandzie marketingowej AI to nadal tylko taka trochę lepsza encyklopedia, która (w miarę) sprawnie gada, rysuje, gra i co tam jeszcze, bo ukradła sreptyliony tekstów, obrazów, muzyki i innych danych. Ejaj nie tworzy żadnych nowych wartości czy znaczeń których nie znajdzie w zbiorach uczących. Rzeczywiste możliwości modeli LLM czy gLLM[39] sprawiają, że mimowolnie nasuwa się porównanie: jeśli samodzielna i świadoma GeneralAI  to byłby Sokół Millenium Hana Solo z “Gwiezdnych wojen”, dzisiejsze modele to latające chińskie lampiony. Niby latają i się palą to mogą gdzieś coś (czy kogoś) podjarać, ale nie wejdą w nadświetlną i gwiazd nie sięgną. Może coś tam zmienią, ale wbrew marketingowym rewelacjom bryły świata z posad nie ruszą.


Dopóki nie doczekamy się superkomputerów kwantowych oraz koherentnej teorii świadomości i rozwiązania paru innych poważnych zagadek w ogóle nie ma co nawet mówić o tworzeniu jakiejkolwiek sztucznej inteligencji z prawdziwego zdarzenia, użycie tego określenia wobec modeli językowych to grube nadużycie, zdolności werbalne to tylko wycinek inteligencji, a myślenie nie jest algorytmiczne, algorytm z definicji jest instruktażem dla debi… inteligentnego inaczej. W każdym razie i te warunki, gdyby nawet zostały spełnione, to najwyżej ewentualność, nie żadna gwarancja. To czym ejaj obecnie jest, to w gruncie rzeczy taki sam symulakr sztucznej inteligencji jakim była Wiktoria, to w istocie nie więcej niż efekciarska imitacja, bezczelnie nazwana “inteligencją”. A co z Wiktorią? Jako że współczesność zdeformowała jej przekaz, wykorzystanie dobrego onegdaj pomysłu i przeprowadzenie remake’u, dziś niepotrzebnej, irracjonalnej i nieskutecznej symulacji możliwości stworzenia rewolucyjnego rozwiązania politycznego, w postaci wygenerowania bota z twarzą skopiowaną ze starej foci, który wypluwa z siebie nie polityczne rozwiązania, ale modelowo ściemnioną pseudoprogresywną propagandę wyekstrahowaną z pierdyliarda zajumanych tekstów i który ani nikomu na nic się nie przyda (w odróżnieniu od np. edukacyjnego bota Marii Skłodowskiej), ani nic nowego nie wymyśli jest nonsensem. Generalnie najlepszym wyjściem w obecnej sytuacji byłoby nie wchodzenie w ogóle do tego zatęchłego, a nie zaklętego zamku AI, gdzie poza biernymi umysłowo klikaczami “ludzie są zbędni”, ludzkość w ekstazie serfuje po równi pochyłej zmieniającej się coraz szybciej w otchłań, a dwuwymiarowi knechci Eschera wciąż krążą po schodach Penrose’a, ale oczywiście jest to niemożliwe. Tym niemniej im dalej od tego cyrku tym lepiej, ci którzy dadzą sobie wmówić że muszą wyrywać do przodu za chwilę mogą znaleźć się daleko z tyłu, z najnowszym modelem chipa kontrolującego w d… 




Bez większych nadziei zapraszam do interakcji: sugerowania i komentowania.




And last but not least podziękowania dla mojego syna, Jana Ewertowskiego za inspirację i wsparcie.






© Rafał Ewertowski 2025


25.05.2025


________________
[1] Pierwotna nazwa testu Turinga to “gra w naśladownictwo”: test stawiał maszynę w roli pretendenta usiłującego udowodnić swoją inteligencję podszywając się pod człowieka za pomocą biegłości w posługiwaniu się językiem naturalnym (wątek rozwinięty w części 3).
[2] Wątki moralne związane z animizacją wytworów cybernetyki.
[3] Awatar to wirtualna bądź robotyczna reprezentacja człowieka, kierującego nim w czasie rzeczywistym, a Pani Skłodowska zdaje się nie żyje. Używając nieprawidłowo tego terminu twórcy chcą jednak podkreślić doskonałe odwzorowanie wiedzy i osobowości pierwowzoru przez bota.
[4] Dodatkowym wyróżnikiem tej sytuacji jest fakt iż wytwory AI nie są przedmiotem prawa autorskiego.
[5] Exemplum wspomniany bot M.Skłodowskiej. A stworzenie takiego bota jest możliwe w zakresie, w jakim Wiktoria miała grać rolę interfejsu graficznego OSW. Sam program o opisanej uprzednio operatywności pozostaje, być może na zawsze poza zasięgiem ludzkich możliwości.
[6] Oczywiście jakość wyniku zależy do pewnego stopnia od jakości promptu, ale to tylko wydanie polecenia, ma być możliwie szczegółowo i precyzyjnie, i tyle. AI i tak nie łapie pewnych niuansów, w tym akurat nie różni się od niektórych ludzi.
[7] Oto kolejne klikbaitowe pseudo ”breaking news“ z których nic nie wynika, tyle że może, a nuż teza Churcha-Turinga może być zagrożona, choć oczywiście jednak nie jest, żartowaliśmy.
[8] O tym w dalszej części tekstu - na pewno nie jest pozytronicznym sztucznym umysłem który zakończy polityczne spory, jaki udawała Wiktoria w 2000 r.
[9] AI jako takiej pewnie nie można tak do końca w czambuł potępiać, ale hurraoptymizm jest męczący, a wężykowaty arywizm i obiecywanie gruszek na wierzbie żeby “przyartyścić” budzi wyłącznie niesmak.
[10] Juliusz Słowacki, poemat dygresyjny “Beniowski”.
[11] Boston Dynamics osiąga spektakularne rezultaty sprzęgając uczenie maszynowe z systemem 3D motion capture w procesie nauki ruchu przez roboty.
[12] Ta pozytywna z pozoru cecha jest jednocześnie poważną wadą, większe pole możliwych zastosowań modeli może przyczyniać się tym bardziej i szybciej do niewykształcania umiejętności grafomotorycznych u dzieci i ich stopniowego zaniku u dorosłych użytkowników.
[13] Nieodłączną składową procesu interakcji człowieka z AI jest symulacja. Ejaj w swojej naturze jest symulacją inteligencji, ciągłą “grą w naśladownictwo”, permanentnym zdawaniem testu Turinga.
[14] Albo grafenowy, czy oparty na sztucznych neuronach wyhodowanych z komórek macierzystych.
[15] Czy AI jest coraz sprytniejsza, a ludzie coraz mniej kompetentni językowo i komunikacyjnie czy po prostu werbalne formy komunikacji są tak ułomne?
[16] “Ale pomimo ich oddalenia od doświadczenia zmysłowego, mamy coś w rodzaju percepcji obiektów teorii mnogości, co widać z faktu, że aksjomaty narzucają się nam jako prawdziwe. Nie widzę żadnego powodu, dla którego mielibyśmy mieć mniejsze zaufanie do tego rodzaju percepcji, tj. do intuicji matematycznej, niż do percepcji zmysłowej.” Kurt Godel.
[17] Film bardzo dobrze się ogląda ale jego wewnętrzna logika jest bardzo bliska tej z filmu “Tenet” Christophera Nolana, czyli z marzeń sennych po zjedzeniu 72 uncjowego steka rodem z Big Texan Steak Ranch, Amarillo, Teksas.
[18] W buddyzmie dla osiągnięcia nirwany kluczowe jest pozostawanie świadomym w momencie śmierci, w tym kontekście fascynujące jest co się dzieje z umysłem praktykującego sokushinbutsu, czyli automumifikację za życia: mumie które opierają się procesom rozkładu jakoby “medytują” po zaniku funkcji życiowych.
[19] “Chodzi mi o to, aby język giętki, Powiedział wszystko, co pomyśli głowa: A czasem był jak piorun jasny, prędki, A czasem smutny jako pieśń stepowa, A czasem jako skarga nimfy miętki, A czasem piękny jak aniołów mowa... Aby przeleciał wszystka ducha skrzydłem. Strofa być winna taktem, nie wędzidłem.” J.Słowacki “Beniowski” pieśń 5.
[20] Kuriozalnym paradoksem jest fakt, że ejaj nie robi w gruncie rzeczy nic innego poza wykonywaniem poleceń, ale symulowanie komunikacji zmienia wszystko.
[21] Może to ewentualnie być droga prowadząca do zupełnie innego rodzaju, wspomnianego w dalszej części tekstu białkowo-krzemowego mariażu mózgu człowieka z komputerem.
[22] Posługują się chwytliwym sloganem reklamowym że stworzyli “umysł w pudełku” (że niby taki jak opisany przez S.Lema) czyli CL1, notabene żeby sprzedawać go za 35tyś$ sztuka, choć po ok. pół roku neurony obumierają).
[23] Lista magazynu Forbes, ale zapewne są tam głównie ci, którzy chcieli się tam znaleźć. Istnieją jeszcze z pewnością tacy, którzy są na tym samym lub nawet wyższym poziomie bogactwa, ale ich pieniądze lubią ciszę, porozkładane są w nieprześledzalny sposób w niezliczonych spółkach i konsorcjach.
[24] Koreański KAIST wprowadza właśnie do urządzeń neuromorficznych układy scalone oparte na półprzewodnikach memrystorowych, umożliwiające autonomiczne korygowanie błędów. Fajnie brzmi, ale to kolejna naciągana  zbieżność wyłącznie nomenklaturowa, podobnie jak w przypadku “inteligencji”. “Autonomia” w wykonywaniu zadań nie ma nic wspólnego z wolną wolą.
[25] Trwają usilne starania o dostęp do nowych danych humanopochodnych: Meta, właściciel Facebooka i Instagrama właśnie zapowiedział użycie publicznych danych użytkowników do szkolenia swoich modeli.
[26] Jeden z objawów tego zjawiska to tzw. slop channels na youtubie, które infekują serwis badziewną treścią generatywną. Choć pojawiają się propozycje takie jak np “trutka na slopy”, to ich siła przebicia będzie pewnie porównywalna z nikłymi skutkami antybanksterskiego apelu sprzed lat o masowe wycofywanie pieniędzy z banków. Żadna, albo pomijalna.
[27] Oczywiście wdrażane są rozwiązania w ramach których m.in. powstają modele weryfikujące, odróżniające treści generatywne, ale może to być nieskończony, nierozstrzygalny wyścig, którego jedynym realnym skutkiem będzie napędzanie dalszej bezsensownej komplikacji algorytmów ejaj.
[28] Według Melvina Vopsona z University of Portsmouth informacja posiada mierzalną masę, a masa przechowywanych na Ziemi bitów informacji przekroczy masę planety za 150 do 1200 lat. 
[29] Nie sposób nie wspomnieć o niebezpieczeństwie uzależnienia emocjonalnego od kontaktu z AI, w tym także o naprawdę już absurdalnym jednostronnym związku uczuciowym.
[30] Kolejna możliwa interpretacja egzystencjalnie genialnego bon motu J.P. Sartre’a "L'enfer, c'est les autres” (Piekło to inni).
[31] Gemini Live ma być darmowy żeby mógł śledzić jak największą liczbę użytkowników.
[32] Rzekomo mają np. umożliwić widzenie niewidomym, więc najpewniej to niepełnosprawni jako pierwsi zostaną marionetkami cyfrowych feudałów, cyberkapitalistycznych “puppet masters”.
[33] Spodziewaj się towarzystwa przygłupiego AI-sawanta śledzącego każdą twoją myśl i wbijającego ci w łeb terabajty ad finem indywidualnie skrojonej propagandy przez 24 godziny na dobę.
[34] Przykład z innych okolic ludzkiego ciała ilustrujący technologiczne tendencje zmierzające do stworzenia transludzkich hybryd.
[35] Już teraz nasilają się tendencje personalizacyjne: najnowszą funkcją modeli ejaj jest “pamiętanie” poprzednich kontaktów z użytkownikiem, jego preferencji, zainteresowań i opinii.
[36] Np: w Polsce panuje obecnie geopolitycznogenna bezprecedensowa rusofobia, podobnie jak komunofobia za czasów McCarthyzmu w USA, a politycy różnych opcji używają jej bez żadnych ograniczeń wyzywając się wzajemnie od “ruskich onuc”, co nie przynosi absolutnie żadnych korzyści społeczeństwu, wręcz przeciwnie. Tylko się uodparniamy na takie zarzuty w przestrzeni publicznej i teraz to już w jakimś sensie prawie wszyscy politycy są rosyjskimi szpiegami. W takim mętnym stawie prawdziwym agentom, których pewnie nie brakuje, pływa się wyśmienicie.
[37] Chiński DeepSeek (w formule open source) pokazał że można je znacząco obniżyć, kradnąc tu i ówdzie jeszcze więcej niż super drogie modele. Świetnie. Znamienne że Chiny od lat są też światowym liderem w społecznej ultra inwigilacji, także przy użyciu narzędzi AI.
[38] W synergii z mediami społecznościowymi wdrażający procesy nowej społeczno-ekonomicznej ery feudalnej.
[39] Modele generatywne (gLLM) to tzw. transformery dekodujące. W odróżnieniu od działających liniowo LLM mają wbudowany mechanizm tzw. dyfuzji, uczący model jak zbudować sekwencję iteracji porządkujących randomowy szum by uzyskać pożądany obraz. Mają większą skłonność do “halucynowania” od algorytmów LLM, to “twórcze” sukinsyny. Malowanie i pisanie.